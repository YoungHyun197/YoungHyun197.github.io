---
title : "Pytorch MNIST 모델"
category :
    - pytorch
tag :
    - pytorch
    - deep-learning
    - machine-learning
toc : true
toc_sticky: true
comments: true
---
MNIST 모델에 대하여 알아보자 


# module import

우선 필요한 모듈들을 import 해준다.

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

import torchvision
import torchvision.datasets
import torchvision.transforms as transforms

import numpy as np
import matplotlib.pyplot as plt
plt.style.use('seaborn-white')
```

# 전처리 설정
- `transform.Compose` :  우리가 원하는 대로 데이터를 핸들링 가능
  
`trochvision.transforms` 모듈을 이용시 `transform` 을 구현할 수 있다. 

파라미터로는 일반적으로 텐서로 형식을 바꿔준 뒤 

Normalize를 통해 (mean ,std)를 설정해준다. 

```python
transform = transforms.Compose([transforms.ToTensor(), # PIL 형식을 Tensor로 바꿔서 사용 
                                transforms.Normalize((0.5, ), (0.5))]) # mean과 std를 0.5씩 
```

# 데이터 로드 및 데이터 확인

```python
# torchvision에서 제공하는 dataset에 MNIST가 있음. 우리는 그것을 사용할 예정
trainset = torchvision.datasets.MNIST(root='./data',
                                      train = True,
                                      download = True,
                                      transform=transform)

testset = torchvision.datasets.MNIST(root='./data',
                                      train = False,
                                      download = True,
                                      transform=transform)
```


```python
# torch.uitls에서 제공하는 dataLoader를 사용하여 우리가 사용할 MNIST 데이터셋을 불러온다.
# 앞서 다운받은 trainset과 testset을 불러옴.
train_loader = DataLoader(trainset,
                          batch_size=128,
                          shuffle=True,
                          num_workers=2)

# testset은 shuffle을 하지 않는다.
test_loader = DataLoader(testset,
                          batch_size=128,
                          shuffle=False,
                          num_workers=2)
```

```python
# train_loader를 image와 label로 분류
image, label = next(iter(train_loader)) 

# 나눈 image, label의 shape을 확인
image.shape, label.shape
# (torch.Size([128, 1, 28, 28]), torch.Size([128]))
```

batchsize를 128로 가져왔기 때문에 맨앞이 128인것을 확인 가능하다.

grayscale은 1, 채널수 28, 입력크기 28 

```python
# 불러온 이미지를 시각화하기위한 함수 작성
def imshow(img):
  img = img / 2 + 0.5 
  npimg = img.numpy() # 이미지를 넘파이로 변환
  fig = plt.figure(figsize=(10, 5))
  plt.imshow(np.transpose(npimg, (1, 2, 0))) # 넘파이 이미지를 (1, 2, 0)으로 tanspose
  plt.show()
```



```python
dataiter = iter(train_loader) # iter는 호출가능한 객체에서 반복을 끝낼 값주면 꺼내오며 반복종료 
images, labels = dataiter.next() # next는 값을 꺼내오는 파이썬 내장함수
imshow(torchvision.utils.make_grid(images[:4])) # make_grid를 통해 이미지를 여러개 가져올수 있음
```
![](/assets/image/2022-03-07-23-55-15.png)

train_loader로부터 이미지가 잘 불러와진 것을 확인할 수 있다. 

```python
class Net(nn.Module):

  def __init__(self):
    super(Net, self).__init__()

    self.conv1 = nn.Conv2d(1, 6, 3) # input 1, output 6
    self.conv2 = nn.Conv2d(6, 16, 3) # input 6, output 16
    self.fc1 = nn.Linear(16 * 5 * 5, 120) # 16 * 5 * 5이미지를 120으로 펴줌
    self.fc2 = nn.Linear(120, 84) # input 120을 output 84로 변경 
    self.fc3 = nn.Linear(84, 10) # input 84를 output 10으로 변경

  # forward 함수를 통해 각 레이어를 연결 
  def forward(self, x): 
    x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # conv1을 relu를 거친후 2x2로 맥스풀링 
    x = F.max_pool2d(F.relu(self.conv2(x)), 2) # conv2을 relu를 거친후 2로 맥스풀링
    x = x.view(-1 ,self.num_flat_features(x)) # view를 통해 이미지를 flat하게 변경후 
    # fc1, 2, 3를 거치도록 해준다.
    x = F.relu(self.fc1(x))
    x = F.relu(self.fc2(x))
    x = self.fc3(x) 
    return x

  # 입력이미지의 크기를 flat하게 구하는 함수 ex) 28x28(2차원)의 이미지를 784 (1차원)로 반환
  def num_flat_features(self, x): 
    size = x.size()[1:] # 입력이미지의 size를 가져온뒤
    num_features = 1
    for s in size: # size의 원소들을 곱하여 전체 feature의 개수를 구한다. 
      num_features *= s

    return num_features
  
net = Net()
print(net)
```

```python
params = list(net.parameters())
print(len(params))
print(params[0].size())
# 10
# torch.Size([6, 1, 3, 3])
```

파라미터의 길이를 확인해보면  최종값은 10이고 

첫번째 layer는 output이 6이므로 6, 1, 3, 3이 나온것을 확인 가능하다. 

첫번째 layer는 params[0]에 담겨있다. 



## 임의의 값을 넣어 Forward값 확인

임의의 1,1,28,28 크기의 입력값을 생성한후 신경망을 통과시킨 결과를 살펴보자.

최종 10개의 값을 가지는 것을 확인 가능하다. 

```python
input=torch.randn(1, 1, 28, 28 )
out = net(input)
print(out)
#tensor([[ 0.1469, -0.0149,  0.0505,  0.0079,  0.0640,  0.0271, -0.0843, -0.2203,
#          0.0197,  0.0231]], grad_fn=<AddmmBackward0>)
```

# 손실함수와 옵티마이저

```python
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr = 0.001, momentum=0.9 )
```

# 모델 학습
- `optimizer.zero_grad` 가중치의 그레디언트 초기화
- loss 계산
- `loss.backward()`
- `optimizer.step()`: 업데이트 

학습은 위 4단계로 이루어진다.


우리가 학습할 데이터의 배치 수를 확인해보자. 

```python
total_batch = len(train_loader)
print(total_batch)
#469
```
469개의 배치를 가지고 있는것을 확인 가능하다. 

```python
for epoch in range(2):

  running_loss = 0.0
  for i, data in enumerate(train_loader, 0):
    inputs, labels = data
    
    optimizer.zero_grad() # 1번과정

    outputs = net(inputs)
    loss = criterion(outputs, labels) # 2번과정 : 예측값과 레이블값을 통해 오차를 구함 
    loss.backward() # 3번과정 : 오차를 역전파 
    optimizer.step() # 4번과정 : 파라미터 업데이트 

    running_loss += loss.item()
    if i % 100 == 99:
      print(f"Epoch : {epoch+1}, Iter: {i+1}, Loss: {running_loss / 100}")
      running_loss =0.0

```

![](/assets/image/2022-03-07-23-37-44.png)

다음과 같이 2번의 epoch만으로도 loss가 상당히 감소하는 것을 확인 가능하다.


# 모델의 저장 및 로드 
- `torch.save` 
   > - `net.state_dict()`를 저장
- `torch.load`
   > - `load_state_dict()`

모델 저장방법

```python
PATH = './mnist_net.pth'
torch.save(net.state_dict(), PATH)
```

모델 불러오기

```python
net = Net()
net.load_state_dict(torch.load(PATH))
```
```python
net.parameters
```
![](/assets/image/2022-03-07-23-52-44.png)

# 모델 테스트

모델을 테스트하기에 앞서 test_loader로 불러온 테스트셋 이미지들을

한번 출력해보자.

```python
dataiter = iter(test_loader)
images, labels = dataiter.next()

imshow(torchvision.utils.make_grid(images[:4]))
```
![](/assets/image/2022-03-07-23-53-13.png)

테스트셋에서 순서대로 4개의 이미지를 가져오면

7, 2, 1, 0이 들어있다.

우리는 우리의 모델이 해당 input들에 대해 각각 7, 2, 1, 0 으로 예측하길 기대한다.

```python
outputs = net(images)  # output을 하나 가져와서 
_, predicted = torch.max(outputs, 1) # 최대값들을 뽑아낸다. (즉 가장 가능성 높은 예측 수치)
print(predicted) 
```

![](/assets/image/2022-03-08-00-05-31.png)

```python
print(''.join('{}\t'.format(str(predicted[j].numpy())) for j in range(4)))
```

![](/assets/image/2022-03-08-00-06-22.png)

앞에 4개의 test이미지에서는 정확하게 예측하고 있다.

그렇다면 전체 테스트 이미지에서의 정확도는 어떤지 확인해보자

```python
correct = 0
total = 0

with torch.no_grad():
  for data in test_loader:
    images, labels = data
    outputs = net(images)
    _, predicted = torch.max(outputs.data, 1)
    total+= labels.size(0)
    correct += (predicted == labels).sum().item()

  print(100 * correct / total)
# 84.34
```
정확도는 84.34로 아주 정확하지는 않음을 알 수 있다. 

이것은 epoch를 2번밖에 돌리지 않았기 때문에 부정확하다고 볼 수 있다.

# GPU 설정 후 학습
```python
use_cuda = torch.cuda.is_available()
device = torch.device("cuda" if use_cuda else "cpu")
```
device 설정후 앞서 작성한 코드들을 그대로 옮겨준다. 

```python
transform = transforms.Compose([transforms.ToTensor(), # PIL 형식을 Tensor로 바꿔서 사용 
                                transforms.Normalize((0.5, ), (0.5))]) # mean과 std를 0.5씩 

# torchvision에서 제공하는 dataset에 MNIST가 있음. 우리는 그것을 사용할 예정
trainset = torchvision.datasets.MNIST(root='./data',
                                      train = True,
                                      download = True,
                                      transform=transform)

testset = torchvision.datasets.MNIST(root='./data',
                                      train = False,
                                      download = True,
                                      transform=transform)

# torch.uitls에서 제공하는 dataLoader를 사용하여 우리가 사용할 MNIST 데이터셋을 불러온다.
# 앞서 다운받은 trainset과 testset을 불러옴.
train_loader = DataLoader(trainset,
                          batch_size=128,
                          shuffle=True,
                          num_workers=2)

# testset은 shuffle을 하지 않는다.
test_loader = DataLoader(testset,
                          batch_size=128,
                          shuffle=False,
                          num_workers=2)

```
```python
class Net(nn.Module):

  def __init__(self):
    super(Net, self).__init__()

    self.conv1 = nn.Conv2d(1, 6, 3) # input 1, output 6
    self.conv2 = nn.Conv2d(6, 16, 3) # input 6, output 16
    self.fc1 = nn.Linear(16 * 5 * 5, 120) # 16 * 5 * 5이미지를 120으로 펴줌
    self.fc2 = nn.Linear(120, 84) # input 120을 output 84로 변경 
    self.fc3 = nn.Linear(84, 10) # input 84를 output 10으로 변경

  # forward 함수를 통해 각 레이어를 연결 
  def forward(self, x): 
    x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # conv1을 relu를 거친후 2x2로 맥스풀링 
    x = F.max_pool2d(F.relu(self.conv2(x)), 2) # conv2을 relu를 거친후 2로 맥스풀링
    x = x.view(-1 ,self.num_flat_features(x)) # view를 통해 이미지를 flat하게 변경후 
    # fc1, 2, 3를 거치도록 해준다.
    x = F.relu(self.fc1(x))
    x = F.relu(self.fc2(x))
    x = self.fc3(x) 
    return x

  # 입력이미지의 크기를 flat하게 구하는 함수 ex) 28x28(2차원)의 이미지를 784 (1차원)로 반환
  def num_flat_features(self, x): 
    size = x.size()[1:] # 입력이미지의 size를 가져온뒤
    num_features = 1
    for s in size: # size의 원소들을 곱하여 전체 feature의 개수를 구한다. 
      num_features *= s

    return num_features
  
net = Net()
print(net)
```

```python
net = Net().to(device)


criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr = 0.001, momentum=0.9 )
```

위와 같이 GPU로 우리가 생성한 모델을 옮겨준다. 

```python
for epoch in range(20):

  running_loss = 0.0
  for i, data in enumerate(train_loader, 0):
    inputs, labels = data[0].to(device), data[1].to(device)
    
    optimizer.zero_grad()

    outputs = net(inputs)
    loss = criterion(outputs, labels) # 예측값과 레이블값을 통해 오차를 구함 
    loss.backward() # 오차를 역전파 
    optimizer.step()

    running_loss += loss.item()
    if i % 100 == 99:
      print(f"Epoch : {epoch+1}, Iter: {i+1}, Loss: {running_loss / 100}")
      running_loss =0.0
```

epoch도 코드를 그대로 적어주면 되는데 다만 GPU 환경에서 사용시 

inputs와 labels를 `.to(device)`를 통해 GPU로 보내주어야한다.

이젠 CPU환경이 아닌 GPU이므로 epoch을 2에서 20으로 증가시킨뒤 

정확도를 확인해보자. 

![](/assets/image/2022-03-08-00-26-33.png)

epoch를 20번으로 증가시키니 2번 했을때 0.7에서 0.05까지 감소하는 것을 확인 가능하다.

```python
correct = 0
total = 0

with torch.no_grad():
  for data in test_loader:
    images, labels = data[0].to(device), data[1].to(device)
    outputs = net(images)
    _, predicted = torch.max(outputs.data, 1)
    total+= labels.size(0)
    correct += (predicted == labels).sum().item()

  print(100 * correct / total)
#98.34
```

주의할 것은 test시에도 images와 labels는 `.to(device)`를 통해 GPU로 보내주자

epoch를 20번으로 증가시켜주니 정확도가 98.34 까지 증가하는 것을 확인가능하다.

이것은 엄청 높은 정확도를 보인다고 할 수 있다. 




