---
title : "Pytorch 기초"
category :
    - pytorch
tag :
    - pytorch
    - deep-learning
    - machine-learning
toc : true
toc_sticky: true
comments: true
---
Pytorch의 구성요소에 대하여 알아보자. 


# 파이토치의 구성요소
- `torch`: 텐서를 생성하는 라이브러리
- `torch.autograd` : 자동미분 기능을 제공하는 라이브러리
- `torch.nn` : 신경망을 생성하는 라이브러리
- `torch.multiprocessing` : 병렬처리 기능을 제공하는 라이브러리
- `torch.utils`: 데이터 조작 등 유틸리티 기능 제공
- `torch.legacy` : Torch로 부터 포팅해온 코드
- `torch.onnx` : ONNX (Open Nural Netwrok Exchange) 
   > 서로 다른 프레임워크 간의 모델을 공유할 때 사용

# 텐서 (Tensors)
- 넘파이의 ndarry와 유사
- GPU를 사용한 연산 가속도 가능

```python
import torch
```

## 초기화 되지 않은 행렬
``` python
x = torch.empty(4 ,2) # 4행 2열
print(x)
```

## 무작위로 초기화된 행렬
``` python
x = torch.rand(4, 2)
print(x)
```

## dtype이 long, 0으로 채워진 텐서
``` python
x = torch.zeros(4, 2, dtype = torch.long)
print(x)
```

``` python
x= torch.tensor([3, 2.3])
print(x)
```

``` python
x = x.new_ones(2, 4, dtpye=torch.double)
print(x)
```

``` python
x = torch.randn_like(x, dtype = torch.float) # dtype 변경 
print(x)
```

## 텐서의 크기
``` python
print(x.size())
```

## 정리
- `torch.empty` : 입력받은 크기의 shape만큼 빈 공간의 torch 생성
- `torch.rand` : 입력받은 shape만큼 random으로 텐서 생성
- `torch.zeros` : 입력받은 크기의 shape 만큼 0으로 해당공간을 채워줌
- `troch.tnesor` : numpy와 유사. 직접 텐서를 생성하는 방법 
- `x.new_ones(2, 4, dtype=torch.double)` : torch의 double 자료형으로 2,4만큼 1로 초기화
- `torch.randn_like` : random으로 채운값의 dtype을 결정하는 방법
- `torch.size()` : torch 텐서의 크기를 반환

## 덧셈

```python
y = torch.rand(2, 4)
print(y)
print(x+y)
```


```python
print(torch.add(x, y))
```


```python
result = torch.empty(2, 4)
torch.add(x, y, out=result)
print(result)
```

- inplace 방식
 > in-place 방식으로 텐서의 값을 변경하는 연산 뒤에는 "_" 가 붙음<br/>
 x.copy_(y), x.t_()
```python
# inplace 방법
print(x)
print(y)
y.add_(x) # y+=x
print(y)
```

## 그 외의 연산
- `torch.sub` : 뺄셈
- `torch.mul` : 곱셈
- `torch.div` : 나눗셈
- `torch.mm` : 내적 (dot product)


```python
x = torch.Tensor([ [1, 3],
                   [5, 7]])
y = torch.Tensor([ [2, 4],
                   [6, 8]])
print(x-y)
print(torch.sub(x, y))
print(x.sub(y))
```

```python
x = torch.Tensor([ [1, 3],
                   [5, 7]])
y = torch.Tensor([ [2, 4],
                   [6, 8]])
print(x*y)
print(torch.mul(x, y))
print(x.mul(y))
```

```python
x = torch.Tensor([ [1, 3],
                   [5, 7]])
y = torch.Tensor([ [2, 4],
                   [6, 8]])
print(x/y)
print(torch.div(x, y))
print(x.div(y))
```
```python
x = torch.Tensor([ [1, 3],
                   [5, 7]])
y = torch.Tensor([ [2, 4],
                   [6, 8]])

print(torch.mm(x, y))
```

# 텐서의 조작(manipulations)
## 인덱싱
- 넘파이처럼 인덱싱 사용 가능

```python
print(x)
print(x[:,1])
```

## view
 - 텐서의 크기나 모양을 변경

 4x5의 tensor를 20으로 쭉 펴준뒤 5x4로 변경 (-1 옵션은 자동)
```python
x = torch.randn(4, 5)
y = x. view(20)
z = x.view(5, -1)

print(x)
print(y)
print(z)
```

## item
 - 텐서에 값이 단 하나라도 존재하면 숫자값을 얻을 수 있음


```python
x = torch.randn(1)
print(x)
print(x.item())
print(x.dtype)
```
- 스칼라값 하나만 존재해야함


값이 두개일 경우 에러 발생
```python
x =torch.randn(2)
print(x)
print(x.item())
print(x.dtype)
```

## squeeze
- 차원을 축소(제거)
  

```python
tensor = torch.rand(1, 3, 3)
tensor.shape
```

참고 : randn은 음수가 나올수있고 rand는 음수가 나올수 없다


```python
t = tensor.squeeze()

print(t)
print(t.shape)
```
1x3x3 에서 3x3 으로 사이즈 축소
## unsqueeze
- 차원을 증가 (생성)


```python
tensor = torch.rand(1, 3, 3)
print(tensor)
print(tensor.shape)
```


```python
t = tensor.unsqueeze(dim=0)
print(t)
print(t.shape)
```
shape이 1x1x3x3 으로 변경 (차원이 하나 증가)

## stack
- 텐서간 결합


```python
x = torch.FloatTensor([1, 4])
y = torch.FloatTensor([2, 5])
z = torch.FloatTensor([3, 6])

print(torch.stack([x, y, z]))
```
[ [1, 4], [2, 5], [3, 6] ] 으로 붙는것을 확인 가능 

## cat
- 텐서를 결합하는 메소드 (concatenate)
- 넘파이의 `stack` 과 유사하지만 쌓을 dim이 존재해야함
- 예를 들어, 해당차원을 늘려준 후 결합


```python
a= torch.randn(1, 1, 3, 3)
b= torch.randn(1, 1, 3, 3)
c = torch.cat((a, b), dim = 0)

print(c)
print(c.size()) # [2, 1, 3, 3]
```
dim=0으로 설정했기 때문에 맨 앞을 기준으로 concat한 것


```python
a= torch.randn(1, 3, 3)
b= torch.randn(1, 3, 3)
c = torch.cat((a, b), dim = 1)

print(c)
print(c.size()) # [1, 6, 3]
```
3차원에서 dim=1로 하게되면 두번째를 기준으로 concat하게 된다. 

**사용자가 어떤 dim으로 연결할지 결정하는 것이 중요**

## chunk
- 텐서를 여러 개로 나눌 때 사용
- 몇 개의 텐서로 나눌 것이냐

```python
tensor = torch.rand(3, 6)
t1, t2, t3 =torch.chunk(tensor, 3, dim=1)
# 6을 3개로 나누므로 (3, 2)가 3개 생성될것임

print(tensor)
print(t1) # (3, 2)
print(t2) # (3, 2)
print(t3) # (3, 2)
```

tensor를 청크의 개수를 3개로 나누되, dim = 1을 기준으로 나누어라


 ## split
 - `chunk`와 동일한 기능이지만 조금 다름
 - 하나의 텐서당 크기가 얼마이냐

```python
tensor = torch.rand(3,6)
t1, t2 = torch.split(tensor, 3, dim=1)
# (3, 6)을 dim=1을 기준으로 크기 3으로 나누면 (3, 3) 2개가 생성됨


print(tensor)
print(t1) # (3, 3)
print(t2) # (3, 3)
```
청크는 하나의 tensor를 몇개로 나눌 것인지에 대한 3을 의미하고 

스플릿은 하나의 tensor가 크기가 몇이냐를 의미한다.

## torch <-> numpy
- torch tensor를 numpy array로 변환 가능
  > - numpy()
  > - from_numpy()

참고 : tensor가 cpu상에 있다면 numpy 배열은 메모리 공간을 공유하므로 <br/>
하나가 변하면 다른 하나도 변한다. 

```python
a = torch.ones(7)
print(a)
```

```python
b = a.numpy()
print(b)
```

```python
# tensor를 numpy로 바꿈
a.add_(1)
print(a)
print(b)
# 메모리가 공유되기 때문에 a에 1을 더해도 b가 값이 바뀌는 것을 확인 가능
```

```python
#넘파이를 토치로 바꿈
import numpy as np

a = np.ones(7)
b = torch.from_numpy(a)
np.add(a, 1, out=a)
print(a)
print(b)
# 마찬가지로 메모리가 공유됨
```

## CUDA Tensors
- `.to` 메소드를 사용하여 텐서를 어떠한 장치로도 옮길 수 있음
- ex) CPU, GPU


```python
import torch
x = torch.randn(1)
print(x)
print(x.item())
print(x.dtype)
```

CPU상에 있는 위 torch를 GPU로 옮길 수 있음 

```python
device = torch.device("cuda" if torch.cuda.is_availabe() else "cpu")
```
cuda가 사용가능하면 cuda, 아니면 cpu값을 가짐.

**자주 등장할 코드이니 꼭 기억하도록 하자.**

```python
y = torch.ones_like(x, device=device)
x= x.to(device) 
z = x+y
print(device)
print(z)
print(z.to)
```

# AUTOGRAD
- `autograd` 패키지는 Tensor의 모든 연산에 대해 자동 미분 제공
- 이는 코드를 어떻게 작성하여 실행하느냐에 따라 역전파가 정의된다는 뜻
- backprop를 위한 미분값을 자동으로 계산

## Tensor
- `data`: tensor 형태의 데이터
- `grad`: data가 거쳐온 layer에 대한 미분값 저장
- `grad_fn` : 미분값을 계산한 함수에 대한 정보 저장 (어떤 함수에 대해서 backprop했는지)
- `requirse_grad` : 속성을 `True`로 설정하면 해당 텐서에서 이루어지는 모든 연산들을 추적하기 시작
- 계산이 완료된 후 `.backward()`를 호출하면 자동으로 `gradient`를 계산할 수 있으며, `.grad`속성에 누적됨
- 기록을 추적하는 것을 중단하게 하려면 `.detach()`를 호출하여 연산기록으로부터 분리
- 기록을 추적하는 것을 방지하기 위해 코드 블럭을 `with torch.no_grad():`로 감싸면 `gradient`는 필요없지만, `requires_grad=True`로 설정되어 학습 가능한 매개변수를 갖는 모델을 평가(evalutate)할 때 유용
- Autograd 구현에서 매우 중요한 클래스 : `Function` 클래스

```python
import torch
```
```python
x = troch.ones(3, 3, requires_grad=True)
print(x)
```

```python
y= x+5
print(y)
```

y에는 grad_fn=`<AddBackward0>` 라는 정보가 추가 된다.

이것은 backprop함수를  `AddBackward0` 라는 오브젝트에 저장했다는 의미이다.

따라서 

```python
print(y.grad_fn)
```
다음과 같이 y의 grad_fn을 삺펴보면 `AddBackward0` 오브젝트가 나오는 것을 확인 가능하다.

```python
z = y*y*2
out = z.mean()

print(z, out)
```
위 경우에는 z에 `MulBackward0`가 붙는 것을 확인 가능하다. 

out에는 `MeanBackward0`가 붙게된다. 

- `requires_grad(...)` 는 기존 텐서의 `requires_grad` 값을 바꿔치기(`in-place`)하여 변경

```python
a = torch.randn(3,3)
a = ((a*3)/(a-1))
print(a.requires_grad) # False

a.requires_grad_(True) 
print(a.requires_grad) # True

b= (a*a).sum() 
print(b.grad_fn) # SumBackward0
```

# 기울기(Gradient)
- 역전파: `.backward()` 를 통해 역전파 계산 가능 
  
```python
out.backward()
print(x.grad)
```

```python
x = torch.randn(3, requires_grad=True)

y = x * 2
while y.data.norm() < 1000:
    y = y * 2

print(y)
```

```python
v = torch.tensor([0.1, 1.0, 0.001], dtype = torch.float)
y.backward(v)

print(x.grad)
```

y에서 backward 할때 v를 넣어준 것

- with torch.no_grad() 를 사용하여 gradeint의 업데이트를 하지 않음

```python
print(x.requires_grad) # True
print((x**2).requires_grad) # True

with torch.no_grad():
    print((x**2).requires_grad) # False
```

- detach(): 내용물(content)은 같지만 requires_grad()가 다른 새로운 Tensor를 가져올 때
  
```python
print(x.requires_grad) # True
y = x.detach()
print(y.requires_grad) # False
print(x.eq(y).all()) # tensor(True)
```

## 자동 미분 흐름 다시보기 (1)

- 계산 흐름
- a -> b-> c-> out

$${\frac{\nabla out}{\nabla a}} = ? $$

- backward()를 통해
- a <- b <- c <- out을 계산하면 ${{\frac{\nabla out}{\nabla a}}}$ 값이 `a.grad`에 채워짐


```python
import torch

a= torch.ones(2,2)
print(a)
```

```python
a = torch.ones(2, 2, requires_grad=True)
print(a)
```

```python
print("a.data:", a) # [[1, 1] ,[1, 1]]
print("a.grad:", a.grad) # None
print("a.grad_fn:", a.grad_fn) # None
```

- ${b = a+2}$

```python
b = a+2 # [[3, 3], [3, 3]] # sumBackward0
print(b)
```
- ${c = b^2}$

```python
c = b**2 # [[9, 9],[9, 9]] # PowBackward0
print(c)
```

```python
out = c.sum() # 36, sumBackward0
print(out) 
```

```python
print(out)
out.backward() # 36, sumBackward0
```

- a 의 grad_fn 이 none인 이유
- 직접적으로 계산한 부분이 없었기 때문 

```python
print("a.data:", a) # [[1, 1] ,[1, 1]]
print("a.grad:", a.grad) # [[6, 6], [6, 6]]
print("a.grad_fn:", a.grad_fn) # None
```
```python
print("b.data:", b.data) # [[3, 3], [3, 3]]
print("b.grad:", b.grad) # None
print("b.grad_fn:", b.grad_fn) # AddBackward0
```

```python
print("c.data:", c.data) # [[9, 9] ,[9, 9]]
print("c.grad:", c.grad) # None
print("c.grad_fn:", c.grad_fn) # PowBackward0
```

```python
print("out.data:", out.data) # [36]
print("out.grad:", out.grad) # None
print("out.grad_fn:", out.grad_fn) # SumBackward0
```

## 자동 미분 흐름 다시보기 (2)
- `grad` 값을 넣어서 `backward`
- 아래의 코드에서 `.grad`값이 None은 gradient 값이 필요하지 않기 때문

```python
x = torch.ones(3, requires_grad = True)
y = (x**2)
z = y**2 + x
out = z.sum()
print(out) # 6, SumBackward0
```

```python
grad = torch.Tensor([0.1, 1, 100])
z.backward(grad)
```

```python
print("x.data:", x.data) # [1, 1, 1]
print("x.grad:", x.grad) # [0.5, 5, 500]
print("x.grad_fn:", x.grad_fn) # None
```

```python
print("y.data:", y.data) # [1, 1, 1]
print("y.grad:", y.grad) # None
print("y.grad_fn:", y.grad_fn) # PowBackward0
```

```python
print("z.data:", z.data) # [2, 2, 2]
print("z.grad:", z.grad) # Zone
print("z.grad_fn:", z.grad_fn) # AddBackward0
```



