---
title : "Pytorch 기초 - nn, multiprocessing, utils..."
category :
    - pytorch
tag :
    - pytorch
    - deep-learning
    - machine-learning
toc : true
toc_sticky: true
comments: true
---
Pytorch의 torch.nn, multiprocessing, utils, legacy, onnx에 대하여 알아보자. 



# 파이토치의 구성요소
- `torch`: 텐서를 생성하는 라이브러리
- `torch.autograd` : 자동미분 기능을 제공하는 라이브러리
- `torch.nn` : 신경망을 생성하는 라이브러리
- `torch.multiprocessing` : 병렬처리 기능을 제공하는 라이브러리
- `torch.utils`: 데이터 조작 등 유틸리티 기능 제공
- `torch.legacy` : Torch로 부터 포팅해온 코드
- `torch.onnx` : ONNX (Open Nural Netwrok Exchange) 
   > 서로 다른 프레임워크 간의 모델을 공유할 때 사용


# nn & nn.functional 
- 두 패키지가 같은 기능이지만 방식이 조금 다름
- 위의 `atugorad` 관련 작업들을 두 패키지를 통해 진행할 수 있음
- 텐서를 직접 다룰 때 `requires_grad`와 같은 방식으로 진행 가능
- 결론적으로, `torch.nn`은 attribute를 활용해 state를 저장하고 활용하고, `torch.nn.functional`로 구현한 함수의 경우에는 인스턴스화 시킬 필요 없이 사용 가능 

# nn 패키지
예시
- Containers
- Covoultion Layers
- Pooling Layers
- Padding Layers
- Non-linear Activations (weighted sum, nonlinearity)
- None-Linear Activations (other)
- Normalization Layers
- Recurrent Layers
- Transformer Layers
- Linear Layers
- Dropout Layers
- Sparse Layers
- Distance Functions
- Loss Functions
- ...

```python
import torch
import torch.nn as nn
```

- Convolution Layer 예시 (1)

```python
m = nn.Conv2d(16, 33, 3, stride=2) # in_channel, out_channel, kernel, stride

m = nn.Conv2d(16, 33, (3, 5), stride = (2, 1), padding(4, 2)) 
# kernel size를 shpae으로 줄 수도 있고 padding도 추가 가능

m = nn.Conv2d(16, 33, (3, 5), stride = (2, 1), padding=(4, 2), dilation= (3, 1))

input = torch.randn(20, 16, 50, 100)
print(input)
output = m(input) #
print(output) # 
```

```python
import torch
import torch.nn.functional as F
```

- Convolution Layer 예시 (2)

```python
filters = torch.randn(8, 4, 3, 3)
inputs = torch.randn(1, 4, 5, 5)
conv = F.conv2d(inputs, filters, padding=1)
conv.shape
```

# Torchvision
- `transforms` : 전처리할 때 사용하는 메소드
- `transforms` 에서 제공하는 클래스 이외에 일반적으로 클래스를 따로 만들어 전처리 진행

- 예시
  > - `DataLoader` 의 인자로 들어갈 `transform`을 미리 정의할 수 있음<br/>
  > - `Compose`를 통해 리스트 안에 순서대로 전처리 진행
  > - 대표적인 예로, `ToTensor()`를 하는 이유는 <br/>
  torchvision이 PIL Image형태로만 입력을 받기 때문에 데이터 처리를 위해서 Tensor 형으로 변환해야함

```python
import torch
import torchvision
import torchivison.transforms as transforms
```

```python
transform = transforms.Compose([transforms.ToTensor(), 
                                transforms.Noramlisze(mean=(0.5, ), std=(0.5,))])
```

# utils.data
 - `Dataset`에는 다양한 데이터셋이 존재 
   > - ex) MNIST, CIFAR10, ...
 - `DataLoader`, `Dataset`을 통해 `batch_szie`, `train`여부,<br/> `transofrm`등을 인자로 넣어 데이터를 어떻게 load할 것인지 정해줄 수 있음.

```python
import torch
from torch.utils.data import Dataset, DataLoader

import torchvision
import torchvision.transforms as transforms
```

```python
trainset =torchvision.datasets.MNIST(root='/content', 
                                    train=True, 
                                    download=True, 
                                    transform=transform)

testset =torchvision.datasets.MNIST(root='/content', 
                                    train=False, 
                                    download=True, 
                                    transform=transform)
```


```python
train_loader = DataLoader(trainset, batch_size=8, shuffle=True, num_workers=2) # 몇개 코어
test_loader = DataLoader(testset, batch_size=8, shuffle=False, num_workers=2)
```

- `batch_size`만큼 데이터를 하나씩 가져옴

```python
dataier = iter(train_loader)
images labels = dataiter.next()
images.shape, labels.shape
```

**(중요) torch에서는 channel(채널)이 앞에옴**
- `channel first`
- tensorflow, keras 등에서는 channel이 뒤에옴 (`channel last`)

# 데이터 확인 
```python
import matplotlib.pyplot as plt
plt.stlye.use('seaborn-white')
```

```python
torch_image = torch.squeeze(images[0]) # squeeze로 차원을 하나 줄여준다
torch_image.shpae # [28, 28]
```

```python
image = torch_image.numpy()
image.shape # (28, 28) # 넘파이로 변환
```

```python
label = labels[0].numpy()
label.sahpe # () 결과 값하나, 즉 스칼라 값
```

```python
label # array(1)
```

```python
plt.title(label)
plt.imshow(image, 'gray')
plt.show()
```

# 각 Layer 설명
```python
import torch
import torch.nn as nn
import torch.nn.fuctional as F
import torch.optim as optim
```

# nn.Conv2d
- `in_channels` : 입력으로 사용할 채널의 개수
- `out_channles` : 출력으로 사용할 채널의 개수
- `kernel_size` : 사용할 커널 사이즈
- `stride` : 사용할 stride 수 
  
```python
nn.Conv2d(in_channels=1, out_channles = 20, kernel_size=5, stride=1)
```

```python
layer = nn.Conv2d(1, 20, 5, 1).to(torch.device('cpu')) # .to는 device 선택시 사용함!
layer # Conv2d(1, 20, kernle_size=(5,5), stride=(1,1))
```
- weight 확인

```python
weight = layer.weight
weight.shape # torch.Size([20, 1, 5, 5])
```

- `weight` 는 `detach()`를 통해 꺼내줘야 `numpy()` 변환이 가능

```python
weight = weight.detach()
```

```python
weight  weight.numpy()
weight.shape # (20, 1, 5, 5)
```

```python
plt.imshow(weight[0, 0, :, :], 'jet')
plt.colorbar()
plt.show()
```

```python
print(images.shape) # torch.Size([8, 1, 28, 28])
```

```python
input_image = torch.unsqueeze(images[0], dim=0) # 차원 하나 늘려주기
```

```python
output_data = layer(input_image) # output에 layer를 통과한 input이 담김
```

```python
output = output_data.data
```

```python
output_arr = output.numpy()
output_arr.shape # (1, 20, 24, 24)
```

```python
plt.figure(figsize=(15, 30))

plt.subplot(131)
plt.title("Input")
plt.imshow(image, 'gray')
plt.subplot(132)
plt.title("Weight")
plt.imshow(weight[0, 0, :, :], 'jet')
plt.subplot(133)
plt.title("Output")
plt.imshow(output_arr[0, 0, :, :], 'gray')
plt.show()
```
# Pooling
- `F.max_pool2d`
  > - stride <br/> 
  > - kernel_size
- `torch.nn.MaxPool2d`도 많이 사용

```python
image.shape # (28, 28)
```

```python
pool= F. max_pool2d(output, 2, 2)
pool.shape
```

- MaxPool Layer는 weight가 없기 때문에 바로 `numpy()` 변환 가능

```python
pool_arr = pool.numpy()
pool_arr.shape #  (1, 20, 12, 12) 
```


```python
plt.figure(figsize=(15, 30))

plt.subplot(131)
plt.title("Input")
plt.imshow(image, 'gray')
plt.subplot(132)
plt.title("Weight")
plt.imshow(weight[0, 0, :, :], 'jet')
plt.subplot(133)
plt.title("Output")
plt.imshow(pool_arr[0, 0, :, :], 'gray')
plt.show()
```

# Linear 
- 1d만 가능. `.view()`를 통해 1로 펼줘줘야함

```python
image = torch.from_numpy(image)
image.shape #[28, 28]
```

```python
flatten = image.view(1, 28 * 28)
flatten.shape # torch.sSize([1, 10])
```

```python
plt.imshow(lin.detach().numpy(), 'jet' ) # detach 하는 이유 : layer에 있는 것이므로
plt.colorbar()
plt.show()
```

# Softmax

```python
with torch.no_grad():
    flatten = image.view(1, 28*28)
    lin = nn.Linear(784, 10)(flatten)
    softmax = F.sotmax(lin, dim=1)
```
```python
softmax
```
```python
np.sum(softmax.numpy()) # 1.000001
```

# F.relu
- ReLU 함수를 적용하는 레이어
- nn.ReLU로도 사용 가능

```python
inputs = torch.randn(4, 3, 28, 28).to(device)
inputs.shape
```

```python
layer = nn.Conv2d(3, 20, 5, 1).to(device)
output = F.relu()
output.shape # ([4, 20, 24, 24])
```

# Optimizer
- `import torch.optim as optim`
- `model` 의 파라미터를 업데이트 
- 예시 )
```python
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)
    optimizer = optim.SGD(model.parameters(), lr = 0.001)
 ```
 - `.zero_grad()`로 초기화
 - `.step()`으로 업데이트



