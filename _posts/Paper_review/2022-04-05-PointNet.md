---
title : "PointNet paper review"
category :
    - CS231n
tag :
    - machine_learning
    - 3D data
    - computer vision
toc : true
toc_sticky: true
comments: true
---
'PointNet'을 읽고 정리해보자.  

![](/assets/image/2022-05-02-23-08-43.png)

3D Vision을 공부하다보면, 가장 영향력있는 논문중 하나로 해당 논문을 꼽을 수 있다.  
PointNet의 논문 제목은 'PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation'이다. 


해당 논문에 대하여 알아보도록 하자.

## 0. 논문 
본 논문은 <font color='#1E90FF'> CVPR 2016 </font>에서 소개되었으며, 현재 인용 8000건 가량 된다.  
원본 논문에 대한 자료는 [arXiv](https://arxiv.org/abs/1512.03385)에서 확인할 수 있다.  


## 1. Introduction

Point cloud로 이루어진 데이터들은 일반적으로 irregular format으로 얻어진다. 이것은 특정 order에 의해 grouping된 상태로 얻어진 것이 아니기에 일반적으로 **polygon, voxel로 point data를 rendering** 한 후 사용해왔다. 

즉, irregular form을 regular form으로 바꾸려는 시도가 있었으나

이러한 변환은 데이터를 불필요하게 대량으로 렌더링 한다.(학습시간, 메모리의 낭비) <br/>

데이터의 quantization을 도입하려는 시도도 있었지만 이 방법은 natural invariances를 해치는 문제가 발생한다.  (continuous space -> discrete space)

PointNet은 **point data를 rendering 하지 않고 Point cloud를 직접 다루는 방법을 제시한 최초의 모델**이다. 

이 방법을 사용하면, 학습과정에서 시간과 메모리의 낭비를 줄일수 있다. 

해당 논문에서는 PointNet이 가져야 하는 **2가지 특성**을 제시한다. 

1. Permutation invariant
    > point cloud는 unordered 데이터 이므로 어떤 순서로 들어오더라도 그 특성이 변화해서는 안된다. <br/>
    > N개의 input이 있을때, N!개의 조합이 가능한데, 어떻게 들어오던간에 출력은 동일해야함. 
2. Rigid motion invariant
    > 어떤 transformation (Translation, Rotation, Reflection, Glide reflection)이 point cloud 내의 모든 점에 취해지더라도 point 간의 거리, 방향은 그대로 유지되어야 함.

PointNet은 raw point cloud를 input으로하여 Classification, Part Segmentation, Semantic Segmentation label등으로 output을 생성한다. 

## 2. Related Work

- Point Cloud Features
    > 통계적 특성을 encode하여 certain transformations에서 invariant하도록 디자인 <br/>
    > ex) intrinsic or extrinsic <br/>
    > local and global features로 분류될 수 있음. 

- Deep Learning on 3D data 
    > Volumetric CNN : voxelized shapes에서 동작하는 3D CNN
    > 하지만, volumetric representation은 data sparsity와 3D conv 연산량에 의한 제약이 존재 <br/><br/>
    > FPNN, Vote3D : very large point clouds 는 불가능 <br/><br/>
    > MultiView CNN : 3D point cloud를 render하여 2D 이미지로 바꾼뒤 2D CNN 사용 시도. <br/><br/>
    > Spectral CNN : manifold meshes에 제약이 존재. non-isometric shapes로 확장하는 방법이 불분명 <br/><br/>
    > Featur-based DNN :3D data를 vector로 변경후 FC net사용. 특징을 추출하는 power에 제약 <br/><br/>

- Deep Learning on Unordered Sets 
    > point clouds는 unordered한 dataset. 하지만 deep learning은 regular input에 초점이 맞춰졌다. 
    > 이에 대한 연구는 별로 없음. 

## 3. Problem Statement 
 원래 point는 x,y,z 뿐만 아니라 extra channels (color, normal etc.) 을 갖지만, 해당 논문에서는 (x, y, z) 좌표계만 사용한다. 

 classification : input을 scene point cloud의 shape에서 샘플링해서 얻거나, 사전에 segmentation 거친 결과를 사용 <br/>
 output은 k개의 클래스에 대해 k score를 갖는다. 그 중 max가 되는 클래스로 분류한다.

 semantic segmentation : input을 part region segmentation에서 얻은 single object 또는 3D scene에서 sub-volume 사용. <br/>
 output은 nxm (n=point 수, m=semantic category 수) score를 사용


## 4. Deep Learning on Point Sets

### 4.1. Properties of Point Sets

아래 3가지 조건은 PointNet에서 상당히 중요시 여겨지는 부분이다.

1. Unordered : N개의 3D Pointsets은 N! permutation에 대하여 invariant 해야한다.
   
2. Interaction among Points : 점들은 isolated 되어 있는 것이 아니라, 이웃점하는 점들과 local geometry 측면에서 의미가 있다. 따라서 모델은 이런 local한 특징을 잘 capture해야한다.  
   
3. Invariance under transformations : 특정 transformation에 대하여 output이 변화하면 안된다. 

### 4.2. PointNet Architecture

![](/assets/image/2022-05-09-16-51-44.png)

논문에서 제시한 3가지 key Module은 다음과 같다.
1. Max Pooling 
2. local and global information combination structure
3. two joint alignment networks

#### Max Pooling

Model을 input에 대하여 invariant 하게 만들기 위해선 3가지 전략을 취할 수 있다.
1) sort input int a canonical order <br/><br/>
   > 고차원 공간에서 point permutation에 stable한 order가 존재하지 않으므로 불가능<br/><br/>
2) treat the input as a sequence to train an RNN <br/><br/>
   > 모든 permutation을 고려한다면 가능하지만, N!이 large scale이 되는 경우에 적용 가능한지 보장 불가능
3) Use a simple symmetric function to aggregate the information from each point
   > mlp와 max pooling을 사용시, general function을 symmetric function으로 근사할 수 있고 <br/><br/>
   > 이것은 permutation invariant를 가능하게한다. (max pooling은 최댓값을 뽑아내므로 입력에 대하여 순서가 상관없기 때문)

![](/assets/image/2022-05-09-17-34-11.png)

즉, point 마다 feature를 만드는 mlp와 symmetric function의 역할을 하면서 global feature를 뽑는 max pooling 함수를 통해서 위와 같은 symmetric function을 구성하는 것이다. 

다수의 mlp(h) 를 통해 각각의 n개의 점에서 1024개의 feature를 만들고 max pooling(g)를 통해 global feature를 생성하고 다시 mlp(r)를 거쳐 k개의 class에 대한 output score가 최종 결과로 나온다. 


#### local and global information combination structure

위에서 진행한 과정은 classification을 위한 network이고 segmentation network에선 조금 다르다.

sementation을 위해서는 **global feature 뿐만 아니라 local feature도 함께 이용되어야 한다.**

classification은 input 전체에 하나의 output만을 계산하지만,

segmentation은 각 pixel별로 output을 계산해야 하므로 **local and global information이 모두 필요하다.**

따라서 **64개의 feature가 생성된 intermediate layer에 maxpooling을 거쳐 생성된 1024개의 feature를 concatenate 시킴**으로써, local and global 정보를 결합한다.

이후 다시 mlp를 통해 point별로 class들에 대한 score m개가 나와 nxm의 shape이 output으로 나오게 된다. 

일부 modification을 통해서 local and global sematic에 대한 quantities 를 예측 가능해진다. 

#### Joint Alignment Network
해당 절에서는 Rigid motion invariant에 대한 솔루션을 다룬다. 

즉, **input에 어떤 transformation이 가해져도 output에 영향을 끼치지 않도록 하는 방법**을 설명한다.

해당 논문에선 T-net 이라는 mini network를 사용하는데 이 방법은 **STN (Spartial Transformer network)** 에서 비롯되었다.

먼저, STN에 대해 간략히 알아보면, 

![](/assets/image/2022-05-09-18-01-42.png)

**rigid motion invariant를 만족시키기 위해 image를 orthogonal하게 만든다.**

즉, 기울어진 숫자를 transform을 적용하여 canonical space(표준이 되는 공간)로 보낸뒤 orthogonal하게 만든다.

이를 통해 변형되지 않은 모습의 이미지를 생성하는 것이다.

위 아이디어를 통해 T-net을 얻어왔다.

![](/assets/image/2022-05-09-18-08-33.png)

먼저 T-net에서 point data들을 canonical space로 보내기 위해 적용되어야 하는 transformation matrix를 계산한다. 

이후 input data에 transformation matrix를 곱한다. 

이러한 T-net은 PointNet에서 총 2번 사용되는데, input transform과 feature transform이 있다. 

input transform에서는 3x3 transform이 진행되어 계산이 수월하나, 

feature transform에서는 64x64 transform이 진행되므로 계산이 복잡하다. (64x64 matrix를 predict해야 하므로) 

이를 위해 다음과 같은 규제항을 추가한다.

![](/assets/image/2022-05-09-18-13-46.png)

(해당 식이 왜 정규화를 시켜주는지 정확한 이해하지는 못하였으나, 맥락은 다음과 같다.)

규제항은 transofrmation matrix를 orthogonal matrix가 되도록 변환해준다. 

transformation matrix가 orthogonal matrix가 되면 input matrix에 곱해도 원래 고유 모양이 바뀌지 않는 

rigid motion이 되기 때문이다. 

(즉 , rigid motion에 대응되는 transformation matrix가 되도록 정규화 식을 추가한 것)



### 4.3. Theoretical Analysis

해당 절은 pointNet이 outlier나 missing data에 대해 왜 강한것인지 수학적으로 접근하는 내용이 나와있다.

(수학적 부분이 아직 많이 부족함을 여기서 느낀다. 자세한 분석은 추후에 더 공부하고 해야겠다.)

이에 대한 이유는 max-pooling을 사용했기 때문이라고 한다. 

## 5. Experiment

### 5.1. Applications
1. 3D Object Classification 
    > 12,311개의 CAD models을 사용하였으며, 대략 3/4, 1/4를 train, test set으로 분리하였음 <br><br>
    > input point cloud는 mesh faces에서 1024개의 point들을 sampling후 unit sphere로 normalize <br><br>
    > data augmentation 으로 up-axis 축을 따라 랜덤하게 rotate 혹은 값에 gaussian noise를 추가 <br><br>

2. 3D Object Part Segmentation
   > part segmentation은 per-point classification problem으로 간주 <br><br>
   > metric으로 shape의 mIoU를 사용. 겹치는 point는 IoU에 포함시켜 측정

3. 3D Part Segmentation
   > 각 point는 (X, Y, Z) 좌표와 (R, G, B) + normalized location 정보를 사용 <br><br>
   > point 하나당 9-dim vector  <br><br>
   > 추가로 hand-craft feature로 locla features, local curvature, normal를 추가하여 12-dim vector 사용

### 5.2. Architecture Design Analysis

![](/assets/image/2022-05-09-18-30-35.png)

FC layer와 max pooling layer를 사용하면 연산속도 향상 가능.

![](/assets/image/2022-05-09-18-30-47.png)

3d object part segmentation에 대한 결과

![](/assets/image/2022-05-09-18-31-51.png)

STN을 적횽하면 성능이 조금 향상됨. rgularization term도 효과가 있다. 

![](/assets/image/2022-05-09-18-32-12.png)

MVCNN, 3DCNN은 성능은 좋으나 conv 연산량이 많음, PointNet은 O(N)이라 빠름.