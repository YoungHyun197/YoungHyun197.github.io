---
title : "CS231n 5강 CNN"
category :
    - CS231n
tag :
    - machine_learning
    - CS231n
    - computer vision
toc : true
toc_sticky: true
comments: true
---
CNN에 대하여 알아보자<br/>

## Convolitional Neural Network

2006년에 Hinton과 Salakhutdnov에 의하여 DNN의 가능성이 제시되었다. <br/>
2012년에는 NN 열풍이 불었고 음성인식에서 좋은 성능을 발휘하였다. <br/>
또한 2012년에 `AlexNet`이 CNN의 현대화를 이루었다. <br/>

이후 CNN은 다양한 분야에서 적용되어 사용되었고 빠른 발전을 이루고 있다. <br/>

앞서 배운 신경망에는 `Fully Connected Layer`가 사용되었다. 

`FC Layer`는 어떤 벡터를 가지고 연산을 한 뒤에 일자로 쭉 펴주는 역할을 한다. <br/>


예를들어 32x32x3 image가 input으로 들어오면 3072 x 1로 쭉 펴주는 것이다. 

![](/assets/image/2022-02-14-18-16-49.png)

하지만 `Convolution Layer`에서는 기존 입력의 구조를 보존시켜준다. 이것이 FC와 CN Layer의 가장 큰 차이이다.

FC에서는 32 x 32 x 3 입력 이미지를 `height` x `width` x `depth`로 인식한다. 

입력 이미지는 `filter`를 거치는데 필터 역시 `height` x `width` x  `depth`로 구성된다.

일반적으로 입력이미지와 필터는 정사각형 크기를 사용하기 때문에 `hegiht` = `width`이고,

필터를 거친 입력이미지는 `filter`의 `depth`만큼 확장된다.

필터는 이미지를 좌측상단에서 순차적으로 우측하단에 도달할때 까지 슬라이딩된다.

즉, 이미지를 슬랑이딩 하면서 공간적으로 내적을 수행하는 것이다.

이때 내적수행을 위해 우리는 W를 길게 펴게된다. 

즉, 32x32x3 image와 5x5x3 filter가 있을때 필터는 w의 가중치를 가지고있으면
$$W^Tx+b$$
와 같이 나타낼 수 있다. 

입력이미지가 필터를 거치고난 결과물을 `activation map` 이라고 부른다.

![](/assets/image/2022-02-14-18-23-45.png)

일반적으로 conv layer에서는 여러개의 필터를 사용하는데 이러한 결과물들을 모은것을<br/>
`activation maps`라 부른다.

필터를 여러개 사용하는 이유는 필터마다 다른 특징을 추출하고 싶기 때문이다. 

예를들면 우리가 6개의 5x5 `filters`를 가지고 있다면 

우리는 6개의 activation map을 얻을 수 있다. 

![](/assets/image/2022-02-14-18-26-21.png)

즉, 입력이미지 32x32x3은 필터들을 거치고 28x28x6이 된다. 

여기서 6은 필터의 개수를 의마한다. 32가 28이 된 이유는 뒤에서 자세히 다룬다.

`ConvNet`은 `conv latyr`가 여러개 쌓인 네트워크이다. 그 사이사이엔 `activation functions`가 들어간다. 

![](/assets/image/2022-02-14-18-29-38.png)

정리하면 
- 각 layer는 여러개의 필터를 가지고
- 각 필터마다 각각의 `activation map`을 생성한다.
- 따라서 여러개의 layer들을 쌓고 나서 보면 
- 결국 각 필터들이 계층적으로 학습하는 것을 볼 수 있다. 

`ConvNet`에서 layer의 계층에 따라 단순/복잡한 특징들이 존재한다.

layer가 얕을땐 단순한 특징들을 학습하고, 깊어질수록 복잡한 특징들을 학습한다.

![](/assets/image/2022-02-14-18-31-04.png)

`ConvNet`은 일반적으로 다음과 같은 구조를 갖는다.

![](/assets/image/2022-02-14-18-33-05.png)

입력이미지는 여러 레이러를 통과하는데

첫 `conv layer`를 통과이후 `non-linear layer`를 통과한다.
> `conv` -> `ReLU`

이러한 패턴을 반복하다가 `Pooling layer`를 거친다. <br/>
`pooling layer`는 `activation maps` **사이즈를 감소**시키는 역할을 한다. 
> `conv` -> `ReLU` -> `conv` -> `ReLU` -> `Pooling layer`

최종단계에서는 `FC Layer`를 거친다.
> `conv` -> `ReLU` -> `conv` -> `ReLU` -> `Pooling layer`-> <br/>
> `conv` -> `ReLU` -> `conv` -> `ReLU` -> `Pooling layer`-> <br/>
> `conv` -> `ReLU` -> `conv` -> `ReLU` -> `Pooling layer`-> <br/>
> `FC Layer`

## CNN 연산과정 

CNN이 어떻게 `spatial dimension` 특징을 잘 유지시키는지 좀 더 자세히 알아보자.

![](/assets/image/2022-02-14-18-38-10.png)

다음과 같이 7x7 입력이미지와 3x3 filter가 존재할때 우리는 필터를

우측으로 슬라이딩하면서 연산을 진행하게 된다. 

![](/assets/image/2022-02-14-18-38-57.png)

최대 오른쪽으로 5번 슬라이딩 할 수 있고 아래로도 5번 이동할 수 있기 때문에

출력은 5x5가된다. 

## stride

이때 슬라이딩 하는 보폭을 `stride`라고 한다. 

![](/assets/image/2022-02-14-18-39-48.png)

다시 7x7 input을 3x3 filter를 가지고 stride 2로 움직여보자.

![](/assets/image/2022-02-14-18-40-29.png)
![](/assets/image/2022-02-14-18-40-37.png)
![](/assets/image/2022-02-14-18-40-49.png)

다음과 같이 우리는 오른쪽으로 3번 아래쪽으로 3번 이동할 수 있다.

따라서 출력은 3x3이 된다. 

하지만 stride가 3이라면 어떨까?

이 부분은 직접해보면 7x7 input에서는 정확히 fit하지 않음을 알 수 있다. 

앞서 진행한 과정을 공식으로 만들어보자.

- N = 입력 차원
- F = 필터 사이즈 
$$ Output Size = (N-F)/stride + 1$$

e.g. N=7, F=3:
- stride 1 => (7-3)/1 + 1 = 5 <br/>
- stride 2 => (7-3)/2 + 1 = 3 <br/>
- stride 3 => (7-3)/3 + 1 = 2.33 (불가능)

## padding

앞서 `conv layer`의 연산방법과 `stride`에 대해 배웠다.

이번엔 `padding`이란 개념에 대해 알아보자.

`padding`이란 테두리에 일정한 값을 채워넣는 것이다. 

보통 `zero-padding`을 많이 사용하는데 테두리에 0을 채워넣으면 된다.

![](/assets/image/2022-02-14-18-47-50.png)

위와 같이 `zero-padding`추가시 어떻게 될까?

입력이미지가 크기가 2만큼 증가했다.

즉 (N-F) / stride + 1 에서 (N-F + 2) / stride + 1로 변경된 것이다.

7x7 input , 3x3 fitler, stride 1, 1 zero-padding

(7 - 3 + 2 ) / 1 + 1 = 7

따라서 출려사이즈는 7x7 이 된다.

그렇다면 제로 패딩을 사용하는 이유는 무엇일까?

출력사이즈를 주의깊게 보면 힌트를 얻을수 있는데

바로 **입력사이즈의 크기를 유지**시켜준다는 것이다. 

그렇다면 여기서 하나의 의문을 가질 수 있다.

Q. `zero-padding` 추가시 모서리에 필요없는 특징을 추가하게 되는것이 아닌가?
> A. 우리가 얻고싶은 값은 영상내에 모서리 부분이고, zero-padding을 통해 기존에 <br/>
> 필터가 닿지 않던 모서리 부분에서도 값을 뽑을 수 있게된다. 

padding을 추가하여 공식을 확장해보자.


- N = 입력 차원
- F = 필터 사이즈 
- P = padding 수 

$$ (N - F + 2 * P) / stride + 1 $$ 

e.g. N=7, stride = 1:
- F = 3 => P = 1 <br/>
- F = 5 => P = 2 <br/>
- F = 7 => P = 3 

zero padding을 사용하는 이유는 **입력 이미지의 크기 보존**인 점에 유의하자

Filter 사이즈가 3일때는 P=1, 5일때는 P=2, 7일때는 P=3으로 해주어야 

입력 이미지의 크기가 보존된다. 

![](/assets/image/2022-02-14-18-58-19.png)

제로패딩을 사용하지 않으면 출력사이즈는 아주 빠르게 줄어든다.

이것은 정보손실을 야기할 수 있고, 원본 이미지를 표현하기 힘들어진다.

따라서 제로패딩을 적절히 사용하는 것은 아주 중요하다.

## Question
1번.

![](/assets/image/2022-02-14-18-59-27.png)

2번.

![](/assets/image/2022-02-14-19-01-16.png)

## Answer
1번.
![](/assets/image/2022-02-14-19-06-10.png)

2번.
![](/assets/image/2022-02-14-19-05-55.png)
> parms의 개수는 Wx + b 를 생각해보면 쉽게 구할 수 있다. <br/>
> 5x5 filter가 input의 depth 3만큼 존재하고 bias가 1개 존재하므로 <br/>
> 5 x 5 x 3 + 1 = 76
> 이러한 필터가 총 10장 존재하므로 정답은 760


## 1x1 Convoutuin Layers

1x1 conv layer는 아주 중요한 역할을 한다. 

이것은 입력의 전체 depth에 대한 내적을 수행하는 것과 같다.

![](/assets/image/2022-02-14-19-11-24.png)

56 x 56 x 64 input과 32 1 x 1 x 64 filters가 주어졌을때,

output size는 

(56-1) / 1 + 1 = 56 

56 x 56 x 32 가 된다. (32는 filter 개수를 의미)

## Receptive Field

`Receptive Filed` : 한 뉴런이 한번에 수용할 수 있는 영역 
 > 가령 5x5 filter 가 존재한다면 한 뉴런의 `receptive filed`는 5x5 이다. 

 ## Pooling Layer

 `Pooling layer` : representation을 작게 만들어준다. 
 > 각각의 activation map에서 독립적으로 작용한다 <br/>
   - 파라미터의 수를 줄이기 위해 사용
   - 공간적인 불변성을 얻는 효과 

`MAX Pooling` : filter 안에 가장 큰 값중 하나를 고르는 것
![](/assets/image/2022-02-14-19-19-58.png)

 > pooling은 겹치지 않는것이 일반적이다. <br/>
  기본적으로 down sample이 목적이므로

Q. Average Pooling vs Max Pooling
 > 뉴런이 얼마나 활성되었는가를 표현하기엔 Max Pooling이 적합

 