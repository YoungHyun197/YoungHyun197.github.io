---
title : "CS231n 3강 Loss Function and Optimization"
category :
    - CS231n
tag :
    - machine_learning
    - CS231n
    - computer vision
toc : true
toc_sticky: true
comments: true
---
손실함수와 최적화에 대하여 알아보자


# Loss Function

`loss function`이란 손실함수를 의미하며, W가 얼마나 **부정확** 한지 알려주는 함수이다.<br/>

`loss funtion`을 최소화하는 파라미터를 찾는 과정을 `optimization` 이라고 한다.<br/>



<img src = "/assets/image/2022-02-07-15-02-03.png" width = "70%" height="70%" >
 
3개의 traning sample이 주어고지고 3개의 클래스가 존재하는 상황에서<br/>
`loss function`을 구해보자.

$$ {
    f(x, W) = Wx
}
$$



앞서 말했다시피 `loss function`이란 W가 얼마나 **부정확** 한지 측정하는 함수이다.<br/>

식으로 나타내면 다음과 같다.

$${
L = \frac{1}{N}\sum_{i}{L_i}(f(x_i, W), y_i)
}
$$

- $L_i$ : 사용할 loss function
- $x_i$ : 입력 이미지 
- $y_i$ : 실제 정답 카테고리 (정수) 
- $W$ : 가중치
- $f(x_i, W)$ : 예측 값
- N : 클래스 수 (여기서는 3)

loss function을 이용해 예측값과 레이블의 차이를 더한후 N으로 나누어주면 L값을 구할 수 있다. 

loss의 한 종류인 `SVM loss`에 대하여 좀 더 자세히 알아보자. <br/>
이미지 내에서 정답을 제외하고 모두 더하면 우리는 `SVM loos`를 구할 수 있다. <br/>

$$
\begin{aligned}
   

L_i &= \sum_{j \neq y_i} 

   \begin{cases}
   0 \quad\qquad\qquad(s_{y_i} \geq s_j+1)  \\
   s_j - s_{y_i} + 1  \quad(otherwise) 
    \end{cases} \\
&= \sum_{j neq {y_i}} max(0, s_j - s_{y_i}+1)&
\end{aligned}
$$

여기서 
$s_1 = cat$ , $s_2 = car$, $s_3 = frog$ 이다. 

우선 고양이를 먼저 살펴보자.<br/>
cat = 3.2, car=5.1, frog=-1.7을 나타내고 있다.  <br/>

- $3.2 < 5.1 + 1$ 이므로 $L_i = 5.1 + 1 - 3.2 = 2.9$
- $3.2 \geq  -1.7 + 1$ 이므로 $L_i = 0$
- $L_1 = 2.9 + 0 = 2.9$

 car를 살펴보면 <br/>
 cat = 1.3, car =4.9 , frog = 2.0을 나타내고 있다. <br/>

 -  $max(0, 1.3 -4.9 + 1) + max(0, 2.0 -4.9 + 1)$
 -  $max(0, -2.6) + max(0, -1.9)$
 -  $L_2 = 0 + 0 = 0$ 

 frog를 살펴보면 <br/>
 cat = 2.2, car =2.5 , frog = -3.1을 나타내고 있다. <br/>

 -  $max(0, 2.2 +3.1 + 1) + max(0, 2.5 +3.1 + 1)$
 -  $max(0, 6.3) + max(0, 6.6)$
 -  $L_3 = 6.3 + 6.6 = 12.9$ 

따라서 최종 Loss인 $L$ 다음과 같다.
$$
L = \frac{1}{N}\sum^{N}_{i=1}L_i
$$
$$L = (2.9 + 0 + 12.9) / 3 = 5.27$$


## Question_1
1. car의 score가 살짝 변한다면 어떤 일이 발생하는가?
   > 이미 car의 score가 높기 때문에 loss의 변화는 없다. 

2. loss가 취할 수 있는 최소값과 최대값은?
   > $$min = 0 and max = \infin $$
3. W를 초기화 할 때, 모든 s를 0에 근사한다. 이때 loss는 어떻게 되는가?
   > 클래스의 수 - 1 <br/>
   트레이닝 처음시작 시 loss가 class - 1이 아니라면 버그가 있는 것. <br/>
   실제로 디버깅에 유용하게 쓰인다. 
4. 합을 구할 때 $j= y_i$ 즉, 정답까지 더하면 어떻게 되는가?
   > loss가 1이 증가한다. ($s_j - s_j + 1 = 1 이 모든 클래스에 추가되기때문$)
5. sum 대신 mean을 이용하면 어떻게 되는가 ? 
   > 단순히 손실함수를 rescale 할 뿐. loss겂울 구하는 데는 크게 영향이 없다. <br/>
   우리는 정답 클래스의 score와 아닌 클래스이 차이에 관심이 있기 때문.
6. Loss function으로 $L_i = \sum_{j \neq y_i}max(0, s_j - s_{y_i}+1)^2$ 을 사용하면?
   > 손실함수의 값이 바뀐다. 잘못 작동할 경우와 잘 작동할 경우의 loss값을 가중시킴<br/>
   손실함수의 주 목적은 얼마나 부정확한가를 측정하는 것임에 주의하자.
7. L=0으로 만드는 W는 unique한가?
   > uniqe하지 않다. 다른 W도 존재한다. 예를들면, 2W도 Loss는 0이다.


우리는 Multiclass SVM Loss를 Numpy를 이용하면 아주 짧은 code로 구현가능하다.
$$L_i = \sum_{j \neq y_i}max(0, s_j - s_{y_i}+1)^2$$
```python
def L_i_vectorized(x, y, W):
   scores = W.dot(x)
   margins = np.maximum(0, scores - scores[y] + 1)
   margins[y] = 0 # max로 나온 결과에서 정답클래스만 0으로 변경
                  # 전체 순회 없이 필요한 부분만 0으로 만드는 vectorized 기법
   loss_i = np.sum(margin)
   return loss_i

```
# Regularization

다양한 W중 loss가 0인것을 선택하는 것은 모순이다. <br/>
오직 갖고 있는 데이터의 loss에 대해서만 신경을 쓴 것이기 때문이다. <br/>
실제로 트레이닝 데이터에 얼마나 일치하는지는 사실 별로 중요하지 않다.<br/>
적용은 테스트 데이터에 하기 때문에 트레이닝 데이터에 loss만 신경쓰면 안되는 것이다.

즉, `Regularization`이란 `model`이 `train set`에 정확히 fit하지 않도록<br/>
**penalty를 부여**해주는 작업이다. <br/>


![](/assets/image/2022-02-08-19-36-25.png)<br/>
단순히 training 데이터에만 일치시킨 경우 <br/>
![](/assets/image/2022-02-08-19-36-38.png)<br/>
이 경우 test 데이터에서 불일치가 심하다. (정확한 예측 x)<br/>
![](/assets/image/2022-02-08-19-36-59.png)<br/>
우리가 원하는 classifer는 초록색 선이다. <br/>

초록색 선과 같이 분류하기 위해서 우리는 정규화가 필요하다.<br/>
이는 모델이 좀 더 단순한 W를 고를수 있도록 도와준다. 

 
$${
L(w) = \frac{1}{N}\sum_{i}{L_i}(f(x_i, W), y_i) + \lambda R(W)
}
$$

해당 강의에서 한 학생이 이러한 질문을 했다. <br/>
어떻게 $Wx + \lambda R$이 곡선을 직선으로 바꿔준다는 것안가?

교수님의 대답은 이러하다.<br/>
복잡한 문제이기에 detail 하게 다루지는 않되, <br/>
일반적으로 모델은 고차 다항식을 이용해서 문제를 풀려고 한다.<br/>
이때 regression term을 추가하면 모델이 data를 fit할 때 저차 다항식을 선호하도록 한다<br/>


Regularization의 주요기능은 다음과 같다. 

- 모델이 더 복잡해지는 것을 방지
- 모델에 soft penaty를 추가 (training 데이터셋에 완전히 일치못하도록 페널티 부여)
   > 여전히 더 복잡한 모델이 될 가능성 존재<br/>
<br/>

Regularization은 이 외에도 여러가지가 존재한다. 
- L1 Regularization
  > W에 페널티 부과 <br/>
  $$L = \frac{1}{N}\sum^{N}_{i=1}{L_i}max(0, f(x_i, W)_j -f(x_i, W)_{y_i} +1) + 
  \lambda R(W)  
$$
- L2 Regularization
  > $$ R(W) = \sum_k\sum_l{W^2{_k,_l}} $$ 
- Elastic net (L1 + L2)
- Max Norm Regulariation 
- Dropout
- Fancier 

L2 Regularization를 이용해 모델의 복잡도를 측정하는 예시를 살펴보자.<br/>

$X = [1, 1, 1, 1,], W_1 = [1, 0 , 0, 0], W_2 = [0,25, 0.25, 0.25, 0.25]$ <br/>
$f(x) = Wx$ 라고 할 때,
$W_1x =  W_2x = 1로 $ 모두 결과는 동일하다. <br/>
하지만, L2 Regularzation에서는 $W_2$를 선호한다. (norm이 더 작기 때문)


부가적으로 L1 Regularization은 $w_1$을 선호한다. 


# Softmax Classifier

앞서 배운 multi-claass `sum loss`에서는 `score` 자체에 대한 해석을 고려하지 않았다.<br/>

단지 정답 클래스가 정답이 아닌 클래스보다 더 높은 스코어를 내기만을 원했을 뿐이다.<br/>

하지만 `Multinomial Logistic Regression`에서는 `score`에 추가적인 의미를 부여한다.
<br/>

이때 사용되는 함수가 `Softmax function`이다. <br/>

  - `scores`에 지수를 취해 양수가 되도록한다.
  - 그 지수들의 합으로 다시 정규화
  - 확률분포를 얻고, 그것이 바로 해당 클래스일 확률이 된다.
  - 모든 확률의 합은 1이다.


$$ L_i = -logP(Y=y_i | X = x_i) $$

loss는 얼마나 부정확한지를 측정하므로 -를 붙인다.

softmax를 거치고 나온값에 -log를 취해주면 다음과 같이 나타낼 수 있다.

$$ L_i = -log\frac{e^{s{y_i}}}{\sum_j e^{sj}} $$

말로만 설명하면 이해하기 어렵기 때문에 예제를 한 번 살펴보자.<br/>

![](/assets/image/2022-02-08-20-23-53.png)

3.2 에 exp를 취하면 $e^{3.2} = 24.5$ <br/>
5.1 에 exp를 취하면 $e^{5.1} = 164.0$ <br/>
1.7 에 exp를 취하면 $e^{-1.7} = 0.18$ <br/>

합이 1이되도록 normalize를 해주면<br/>
각각 [0.13, 0.87, 0.00] 이 나온다

$$ L_i = -log\frac{e^{s{y_i}}}{\sum_j e^{sj}} $$


이므로 이때 cat에 대한 loss값은 $L_i = -log(0.13) = 0.89$ 이다. 

## Qustion_2
- $L_i$의 최소값과 최댓값은?
  > $$ min = 0, max = \infin$$
- W를 초기화시 s=0에 수렴하는데 이때, loss값은?
  > $$ -log(\frac{1}{C}) = log C$$
   하나의 디버깅 전략으로 이용가능 (실제로도 많이 사용하는 방법)

`SVM` 에서의 loss는 `hinge loss` 라고 부른다.<br/>
`Softmax` 에서의 loss는 `cross-entropy loss` 라고 부른다<br/>

간단히 비교한 그림을 살펴보자.

![](/assets/image/2022-02-08-20-34-04.png)

`SVM`에서는 margin을 신경쓰고 <br/>
`Softmax`에서는 -log(P(정답클래스)) 를 구한다.<br/>

# Optimization
어떻게 실제 loss를 줄이는 최적의 W를 찾을수 있을까? <br/>
해당 과정을 `Opitmization` 이라고 한다. 자세히 살펴보자. <br/>


우리가 산속에 있다고 가정해보자 <br/>
이때, W = 풍경, Loss = 내가 있는 곳의 높이 로 비유할 수 있다. <br/>
Loss는 W에 따라 변함에 유의하자. 

오래전부터 `Opitmization`에 관한 연구가 이어져왔고 다양한 전략이 존재한다. <br/>

첫번째 전략은 `Random Serach`이다. <br/>
임의로 샘플링한 W들을 엄청 많이 모아놓고 Loss를 계산해서 <br/>
어떤 W가 좋은지 탐색하는 방법이다. <br/>

하지만 이 방법은 **절대 사용해서는 안된다.**

그 이유중 하나는 정확도가 아주 낮기 때문이다. 

두번째 전략은 `Follow the slope`이다. <br/>
`slope` 는 어떤 함수에 대한 미분값을 의마한다. <br/>

$$\frac{df(x)}{dx} = \lim_{h\rarr0}\frac{f(x+h)-f(x)}{h}$$

각 점에서 gradeint를 계산하는 방법으로 **Numercial gradeint** 라고 부른다. <br/>

즉, 어떠한 점에서 gradient를 구한다면 그 점에서의 loss에 대한 기울기를 구할 수 있다.<br/>
이러한 방법을 `Gradient Descent` 라고 부른다. <br/>
![](/assets/image/2022-02-08-20-49-35.png)

하지만, 모든 점에대해 gradient를 구하는 것은 쉬운일이 아니다. <br/>
또한 data의 수가 많아지면 연산량이 매우 많아진다. <br/>

따라서 우리는 여러한 점을 하나의 배치로 묶어서 배치단위로 계산한다.<br/>
이것을 `Stochastic Gradient`라고 부른다. 뒤에서 조금 더 자세히 다뤄보자. 

위 방법에서는 gradient를 직접 계산하고 있다. <br/>
각각의 점에대한 gradient를 **직접 계산하는 것이 아니라** <br/>
**미분식을 이용** 하면 보다 정확하고 빠르게 구할 수 있다. <br/>
이것이 세번째 전략이다.  (**analytic gradient**)

이 방법을 `Stochastic Gradient Descent`라 한다. 

정리하면 
- `Numercial gradeint` : 근사값, 느림, 작성하기 쉬움
- `Analytic gradient` : 정확함, 빠름, 오류발생 가능


조금 더 자세히 알아보자. 
## Gradient Descent

$$ L(W) = \frac{1}{N} \sum_{i=1}^{N}L_i(x_i, y_i, W) + \lambda R(W)$$
```python
while True:
   # W를 임의의 값으로 초기화 후 loss, gradient를 계산한다.
   # 이후 가중치를 gradient 반대 방향(-)으로 update 한다. 
   weights_grad = evalutate_gradient(loss_fun, data, weights)
   weigths += -step_size * weights_grad 
```

## Stochastic Gradient Descent(SGD)

$$ \nabla_W L(W) = \frac{1}{N} \sum_{i=1}^{N} \nabla_W L_i(x_i, y_i, W) + \lambda \nabla_W  R(W)$$

```python
while True:
   # 전체 dataset의 gradeint, loss 계산 x => minibatch의 gradient, loss 계산 (2의 거듭제곱)
   data_batch = sample_training_data(data, 256)
   weights_grad = evaluate_gradient(loss_fun, data_batch weights)
   weights += - step_size * weights_grad  
```


# Image Features vs ConvNets
![](/assets/image/2022-02-08-21-25-50.png)

2장에서 설명했듯이 기존에 deep learning이 존재하기 전에는 <br/>
이미지를 처리할때 주로 feature를 직접 추출해서 사용했다.<br/>
현재는 Nueral Network에 input으로 넘겨주는 방식을 주로 이용한다. 

## Image Features 기법

- 이미지의 여러가지 특징 표현을 계산
  > 특징 표현들을 연결시켜 하나의 특징벡터 생성
- Motivation
  > 비선형 데이터를 극좌표계로 변환하면 linear classifer로 분리가능
- Color Histogram
  > 이미지에서 Hue값만 뽑아 모든 픽셀을 각 양동이에 저장<br/>
  한 픽셀은 해당하는 색의 양동이에 넣고 각 양동이에 들어있는 픽셀 개수를 count
- Histogram of Oreiented Gradients (HoG)
- Bag of Words
  > NLP에서 영감을 얻음, 발생빈도를 이용. <br/>
   이미지를 임의로 조각하고 군집화하는 과정을 거침<br/>
   image를 encoding

## ConvNets 
ConvNet은 5장에서 자세히 다루도록 한다. <br/>
다만 ConvNet에서는 Feature를 추출하는 과정이 생략되고 <br/>
Neural Network가 알아서 학습하는데 가장 큰 차이가 있다.


