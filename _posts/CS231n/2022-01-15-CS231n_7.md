---
title : "CS231n 7강 Training NN(2)"
category :
    - CS231n
tag :
    - machine_learning
    - CS231n
    - computer vision
toc : true
toc_sticky: true
comments: true
---
신경망 학습에 대하여 알아보자


지난 시간엔 데이터 전처리에 대해 배웠다.

![](/assets/image/2022-02-18-22-32-11.png)

`normailization` 이전에는 손실함수가 아주 약간의 가중치 변화에도 예민하게 변화한다.

`normalization` 을 하게되면 데이터의 중심을 원점에 맞추고 (zero-cneter)

unit variance로 만들어주게 된다. 

이 경우 최적화가 더 쉽고 학습이 잘된다. 

오늘은 
- Fancier Optimization
- Regularization
- Transfer Leaning

에 대해서 배워보자

# Fancier Optimization


## SGD (Stochastic Gradient)
우선 가장 간단한 최적화 알고리즘을 살펴보자

```python
# Vanila Gradinet Descent

while True:
   weights_grad = evalute_gradient(loss_fun, data, weighs)
   weights += - step_size * weights_grad # perform parameter update 
```

바로 Stocahstic Gradient Descent 이다.

1. 미니배치 안의 data에서 loss를 계산
2. gradeint의 반대방향으로 weight 벡터를 update
3. 1,2를 반복하면 결국 아래 사진의 붉은색의 수렴하고 loss는 감소한다. 

![](/assets/image/2022-02-18-22-36-54.png)

해당 방법의 문제점에 대해서도 살펴보자.
- w1, w2가 있을때 둘중 하나는 update를 해도 손실 함수가 아주 느리게 변한다.
   > gradeint 방향이 고르지 못하기 때문에 지그재그 발생 <br/>
   ex) 수평축은 천천히 수직축은 급격히 변화 <br/>
    고차원으로 갈수록 이 현상은 더 심해진다. 

![](/assets/image/2022-02-18-22-38-17.png)

Q. loss가 한 방향으로는 빠르게, 다른 방향으론 느리게 변할경우 어떻게 될까?
 > 빠른 방향으로 학습이 가중되고 느린 방향으로는 학습이 덜 진행된다.

Q. loss function이 local minima 혹은 saddle point를 가지면 어떻게 될까?
 > 1. local minima 경우 oppostie gradient =0이 됨<br/>
> 2. saddle point 경우 한쪽 방향으로는 증가하고 다른 한쪽방향으론 감소한다.<br/>
> 고차원 공간에서 saddle point가 의미하는 것은 어떤 방향으론 loss가 증가하고 <br/>
> 몇몇 방향은 loss가 감소한다. 따라서 depp neural network는 local minimum보다 <br/>
> saddle point에 취약하다.
   
![](/assets/image/2022-02-18-22-48-32.png)
> saddle point 근처에서 gradient는 0이 아니지만 기울기가 아주 작다 <br/>
> gradient를 계산해서 update해도 기울기가 아주 작기 때문에 현재 가중치의 위치가 <br/>
> saddle point 근처라면 update는 아주 느리게 진행된다. 


SGD를 이용하여 손실함수 계산시 엄청 많은 training set 각각의 loss를 전부 계산해야 한다.

그래서 실제로는 미니배치의 데이터들만 가지고 loss를 추정한다. 

이 방법은 매번 정확한 gradient를 얻을수 없다. 추정한 값만 구할뿐이다.

따라서 noise가 존재하고 minima까지 도달하는데도 시간이 오래걸린다. 

![](/assets/image/2022-02-18-22-52-32.png)

## SGD + Momentum
**gradeint 계산시 velocity를 이용해보면 어떨까?**

위 아이딩로 나온 방법이 SGD에 모멘텀을 추가한 방식이다.

기존 SGD는
$$x_{t+1} = x_t - \alpha \nabla f(x_t)$$

``` python
while True:
   dx = compute_gradient(x)
   x += learning_rate * dx 
```

SGD + Momentum
$$v_{t+1} = \rho v_t + \nabla f(x_t) \\ x_{t+1} = x_t - \alpha v_{t+1}$$


```python
vx = 0
while True:
   dx = compute_gradient(x)
   vx = rho * vx + dx
   x += learning_rate * vx
```

여기서 rho 는 추가된 하이퍼파라미터 (모멘텀 비율을 의미)로

 보통 0.9와 같은 높은값으로 설정한다. 

SGD에 모멘텀을 추가하게 될 경우

공이 굴러 내려가는 상황과 유사하다고 볼 수 있다.

local minimum에 도달해도 여전히 velocity를 가지고 있기 때문에 

gradinet는 0이라도 움직일 수 있다.

![](/assets/image/2022-02-18-23-08-58.png)


## Nesterov Momentum
![](/assets/image/2022-02-18-23-09-39.png)

앞서 배운 모멘텀을 추가하는 방식은

현재지점에서 gradient를 계산후 veclocity와 결합하는 방식이다.

반면 `Nestrerov Momentum`은  우선 velocity 방향으로 움직이고

그 지점에서의 gradient를 계산하는 방식이다. 그리고 다시 원점으로 돌아가

그 둘을 결합한다.

vecloicty 방향이 잘못되었을 경우에는 

현재 gradeint 방향을 좀 더 활용할 수 있도록 해주는 방식이다.

하지만 Neural Network와 같은 non-convex problem에서는 성능을 보장할 수 없다.

$$ v_{t+1} = \rho v_t - \alpha \nabla f (x_t + \rho v_t) $$
$$ x_{t+1} = x_t + v_{t+1} $$

위 식에서 변수들을 적절히 바꾸면 loss와 gradient를 같은 점에서 계산가능하다.


${\hat{x_t} = x_t + \rho v_t}$$ 로 변형한뒤

$$ v_{t+1} = \rho v_t - \alpha \nabla f(\hat{x_t}) \\ 
   \hat{x_{t+1}} = \hat{x_t} - \rho v_t + (1 + \rho)v_{t+1}
$$

## AdaGrad

이 방법은 훈련 도중 계산되는 gradient를 활용하는 방법이다.

velocity term 대신 grad sqared term을 이용한다.

- 학습 도중에 계산되는 gradient에 제곱을 해서 계속 더해준뒤에

- update 할 때 update term을 앞서 계산한 gradeint 제곱항으로 나누어준다.

``` python
grad_squared = 0
while True:
   dx = compute_gradient(x)
   grad_sqaured += dx * dx 
   x -= learning_rate * dx / (np.sqrt(grad_sqaured) + 1e-7)
```

![](/assets/image/2022-02-18-23-49-40.png)

Q. condition number인 경우 (np.sqrt(grad_sqaured) + 1e-7) 값은?
 > A. small dimension에서는 gradient의 제곱 값 합이 작다. <br/>
 이 작은 값이 나눠지므로 가속도가 붙는다.<br/>
 large dimension에서는 gradient가 큰 값이므로 큰 값이 나눠진다. <br/>
 따라서 속도가 점점 줄어든다. 

 Q. Adagrad를 진행할 수록 어떤일이 발생하는가?
   > A. 값이 점점 작아진다. <br/>
   업데이트한  gradient의 제곱이 계속해서 더해지므로 이 값은 서서히 증가한다.<br/>
   이 증가한 값으로 나눠주게 되면 step size는 점점 더 작은 값이 된다.

   손실함수가 convex한 경우에 점점 작아지는 것은 좋은 특징이 될 수 있다.

   convex case에서는 minimum에 근접하면 서서히 속도를 줄여서 수렴하면 아주 좋다.

   하지만 non-convex case에서는 문제가 발생한다.

   saddle point에 걸려버렸을 때 AdaGrad는 점점 멈춰버릴 수 있다. 

   ## RMSProp
   
``` python
grad_squared = 0
while True:
   dx = compute_gradient(x)
   grad_sqaured = dexcay_rate * grad_squared + (1 - decay_rate) * dx * dx
   x -= learning_rate * dx / (np.sqrt(grad_sqaured) + 1e-7)
```

기존의 누적값에 dexcay_rate를 곱해주는 방식이다.

현재 gradeint 제곱은 (1-decay_rate)를 곱해주고 더해준다. 

보통 decay_rate는 0.9 또는 0.99를 사용한다.

## Adam

Adam은 가장 많이 쓰이는 방법이다.

``` python
first_moment = 0
second_moment = 0

while True:
   dx = compute_gradient(x)
   first_moment = beta1 * first_moment + (1 - beta1) * dx
   second_moment = beta2 * second_moment + (1 - beta2) * dx * dx
   x -= learning_rate * first_moment / (np.sqrt(second_moment) + 1e-7)
```
   
first moment는 velocity를 담당한다.

second moment는 초기에 0으로 초기화하고, 1회 update 이후에도

여전히 0에 가깝다. update step에서 second moment로 나누면 초기 step이

엄청나게 커진다.

이 커진 step이 실제로 손실함수가 가파르기 때문이 아니라는것에 주의하자

이값은 seocnd moment를 0으로 초기화 시켰기 때문에 발생하는 인공적인 현상이다.

여기에 bais term을 추가하면 다음과 같다.

``` python
first_moment = 0
second_moment = 0

for t in range(1, num_itreations):
   dx = compute_gradient(x)
   first_moment = beta1 * first_moment + (1 - beta1) * dx
   second_moment = beta2 * second_moment + (1 - beta2) * dx * dx

   fist_unbias = first_moment / (1 - beta1 ** t)
   second_unbias = second_moment / (1 - beta2 ** t)

   x -= learning_rate * first_moment / (np.sqrt(second_moment) + 1e-7)
```

실제로 Adam은 매우 성능이 좋다.

beta1 = 0.9, beta2 = 0.99로 설정하고 lr을 1e-3~1e-4 정도로만 설정하면

모든 아키텍쳐에서 잘 동작한다.

Adam을 이용하면 각 차원마다 적절하게 속도를 높이고 줄이면서

독립적으르ㅗ step을 조절한다.

손실함수가 각 방향으로 정렬되지 않고 기울어진 타원이라면

Adam은 차원에 해당하는 축만을 조절할 수 있다.

즉 **수평 수직축으로는 조절이 되나 회전은 불가능하다**

![](/assets/image/2022-02-19-00-02-32.png)


하이퍼파라미터로서 learning rate를 설정하는 다양한 방법이 존재한다.

1. step decay
   > 처음엔 learning rate를 높게 하고 <br/>
   나중엔 learning rate을 높게 하는 방법이다.

2. exponetial decay
3. 1/t decay

![](/assets/image/2022-02-19-00-04-26.png)

위 그림은 Resnet 논문에 있는 그림인데 현재 수렴을 잘 하고 있는 상황에서

gradient가 점점 작아질때 lr을 낮추어야 한다.

lr이 너무 깊은 깊게 갈수가 없기 때문이다. 

따라서 우리는

1. 우선 decay 없이 학습한다.
2. loss curve를 잘 살피고 있다가 decay가 필요한 곳이 어디인지 고려

다음 방법을 적용하면 된다. 

![](/assets/image/2022-02-19-00-05-54.png)

1. gradient 정보를 이용해서 손실함수를 선형함수로 근사시킨다. 
2. 이 1차 근사함수를 실제 손실함수라고 가정하고 step을 내려간다.
   > 하지만 이 근사함수로는 멀리 갈 수 없다.


![](/assets/image/2022-02-19-00-06-53.png)
좀더 나은 방법으로는 2차 근사 정보를 추가적으로 활용할 수 있다.

해당예시를 다차원으로 확장시키면 Newton step 이라고 한다. 


## L-BFGS

위 방법은 사실상 DNN에서는 잘 사용되지 않는 방법이다.

Stochastic case에서는 잘 동작하지 않는다.

non-convex problems에도 부적합하다.

## 정리

따라서 실제로 Adam을 가장 많이 사용한다.

하지만 full batch update가 가능하고 sthochasticity가 적은 경우라면

L-BFGS가 가장 좋은 선택이 될 수있다.

![](/assets/image/2022-02-20-17-16-27.png)

train error에 대해서 좀 더 자세히 다뤄보자.

우리가 일반적으로 원하는 것은 test, train 사이의 gap을 줄이는 것이다.

Q. 손실함수의 최적화를 마친 상황에서 한번도 보지못한 데이터에서의 성능을 올리기 위해선 어떻게 해야할까?
 > A . 모델을 하나만 학습시키지 말고 10개의 모델을 독립적으로 학습 후 <br/>
 10개 모델 결과의 평균을 이용하는 것이 하나의 방법이 될 수 있다.

 이렇게 여러가지 모델을 합치는 방법을 `앙상블 기법` 이라고 한다.

 1. 여러개의 독립적인 모델을 학습
 2. 테스트타임에서 결과들의 평균을 이용

이 방법을 사용하게 되면 약 2%의 성능이 향상되는 것을 볼 수 있다. 


![](/assets/image/2022-02-20-17-18-55.png)

학습도중 중간 모델들을 저장(snap shot) 하고 앙상블로 사용한다.

Test time에는 여러가지 snapshots에서 나온 예측값들을 평균내서 사용하는 것.

이것이 바로 앙상블 기법이다.

Q. 모델간의 loss 차이가 크면 한쪽이 overfitting일 수 있으니 별로 안좋고 또 차이가 작아도 안좋지 않을까?
 > A. gap이 중요한 것이 아니라 validation set의 성능을 최대화 시키는 것이 중요

Q. 앙상블 모델마다 하이퍼 파라미터를 동일하게 줘야하는가? 
> A. 아니다, 다양한 모델사이즈, lr, regularization 기법등을 앙상블 할 수 있음.

또 다른 방법으로는 학습하는 동안에 

파라미터의 exponentially decaying average를 계속 계산하는 방법이 있다.

check points에서의 파라미터를 그대로 쓰지 않고 

smoothly decaying average를 사용할 수도 있다. 

하지만 결국 **가장 중요한 것은 단일모델의 성능을 향상시키는 것**이다.

이것은 `Regularization`을 이용하면 된다. 

# Regularization 

정규화에서는 loss term을 더하는 방법이 이용된다. 

$$ L = \frac{1}{N}\sum ^N_{i=1} \sum_{j\neq{y_i}}max(0, f(x_i; W)_j - f(x_i; W)_{y_i} + 1) + \lambda R(W)$$

정규화는 다양한 방법이 존재하는데 대표적으로 

- L1 Regularization <br/>
  > $$ R(W) = \sum_k \sum_l | W_{k,l} |$$
  
- L2 Regularization
  > $$ R(W) = \sum_k \sum_l W^2_{k,l}$$
- Elastic net (L1 + L2)
  > $$ R(W) = \sum_k \sum_l \beta W^2_{k,l} +| W_{k,l} | $$
가 있다.


## Dropout
그 외에 방법으로 `Drouout`이라는 것이 있다. 

- froward pass 과정에서 임의의 일부 뉴런을 0으로 만드는것.
- conv layer의 경우 여러 channels이 있으므로 일부 channel 자체를 dropout

![](/assets/image/2022-02-20-17-56-17.png)

Q. 일부 값들을 0으로 만들며 training time의 네트워크를 심각하게 훼손시키는 방법이 과연 좋은 idea라고 할수 있을까?
> A. 특징들간의 상호작용을 방지하기 때문에 <br/>
> 네트워크가 어떤 일부 features에만 의존하지 못하게 해준다. <br/><br/>
 이것은 overfitting을 방지해준다. 또한 단일 모델로 앙상블 효과를 가지게 해준다.

Test time에는 샘플링을 통해서 적분을 근사한다.

Z를 여러번 sampling하여 test time에 average out 시킨다.

이렇게 되어도 여전히 randomness는 존재한다. 

 참고로 batch normalization도 정규화를 하므로 

 일반적으로 drop out과 함께 사용하지는 않는다.

 ## Data Augmentation

 train할때 이미지의 patch를 random하게 잡아내거나 

 이미지를 반전시킨뒤 train dataset에 추가시키는 방법이다. 

 그 외에 밝기값을 바꿔주는 경우도 있다. 

 ![](/assets/image/2022-02-20-18-04-47.png)

 `Data Augmentation`은 어떤문제에도 적용해 볼 수 있는 아주 일반적인 방법이다.

 Test Time에 입력데이터에 임의의 변환을 시켜주게 되면

 일종의 **regularization 효과를 얻을 수 있다. **

 train time에는 stochasitcity가 추가되고

 test time에는 marginalize out 되기 때문이다. 

 ![](/assets/image/2022-02-20-18-06-32.png)

 이 외에도 다양한 regularization 방법이 존재한다.

 # Transfer Learning 

 `Transfer Learning` 이란 전이학습이라고도 불린다.
 - 이미 pretrained된 모델을 이용하여 우리가 이용하는 목적에 맞게 fine tuning하는 방법

 1. 최종 feature와 class scores간의 연결을 초기화한다.
 2. 이후 새로 정의한 가중치행렬을 초기화하고 나머지 이전의 모든 layer들의 가중치는 고정
   
즉 , 오로지 마지막 layer만 가지고 우리 데이터를 학습시키는 것이다.

아주 작은 dataset 일지라도 아주 잘 동작하는 모델을 만들 수 있다.

![](/assets/image/2022-02-20-18-09-47.png)
![](/assets/image/2022-02-20-18-09-57.png)
![](/assets/image/2022-02-20-18-10-11.png)