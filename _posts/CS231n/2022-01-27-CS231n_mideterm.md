---
title : "CS231n Midterm 해설 및 정리"
category :
    - CS231n
tag :
    - machine_learning
    - CS231n
    - computer vision
toc : true
toc_sticky: true
comments: true
---

이번 포스팅에서는 cs231n에서 제공하는 공식 중간고사를 풀이 해보려고 한다.<br/>

혼자 문제를 풀어보고 채점을 했지만, 생각보다 문제 수준이 어려워 놀랐다.<br/>
스스로 부족함을 깨닫고 다시 개념을 정리하였다. 위와 관련된 해설을 아주 잘 해놓은<br/>
블로그를 찾아서 많은 도움을 얻었고 관련 링크를 첨부한다. <br/>

https://shate-programming.tistory.com/76 1-2번 풀이 <br/>
https://biology-statistics-programming.tistory.com/71 3번 풀이 <br/>

필자보다 훌륭하신 분들이 깔끔한 해설을 해놓았기에 디테일한 풀이보다는 문제를 풀며 <br/>
들었던 생각 혹은 부족했던 개념을 되짚어 보는 위주로 서술하겠다. <br/>


# 1-1번

![](/assets/img2022-01-26-15-41-11.png)
loss에 대한 확실한 개념이 없으면 헷갈릴만한 문제 였다.<br/>
아래 그림과 같이 learning rate가 너무 큰 경우 overshooting이 발생하고<br/>
너무 작은 경우에는 매우 천천히 수렴한다. 따라서 loss가 flat하게 줄어드는 것이다. <br/>
<br/>
c의 경우 단순히 데이터셋의 특정 클래스가 많이 분포하면 해당 클래스로 분류되는 경우가 많을 뿐 <br/>
손실함수와 직접적인 연관은 없다. 개인적으로 매력적인 오답이라 생각이 들었다. 

![](/assets/img/2022-01-26-13-27-59.png)

<br/>

# 1-2번

![](/assets/img/2022-01-26-15-45-10.png)

CNN에 대한 개념이 확실하지 않으면 틀릴 수 있을법한 문제라는 생각이 든다.<br/>
`output size = (N-F+2P) / stride + 1`  <br/>
`paramters = channel 수 * (F * F * depth)` <br/>

두 공식을 다시 한번 새겨놓고 가자. 

VGGNet은 기본적으로 224 x 224 images를 input으로 받는다. <br/>
`output size` = (224- 3 + 2) / 1 + 1 = 224 <br/>
conv layer통과후 224 x 224 이고, pooling layer를 통과하면 <br/>
`output size` = (224 - 2 ) / 2 + 1 = 112 <br/>
반으로 줄어든다. pooling layer를 총 4번 더 거치면 FC직전의 shape은 <br/>
7 x 7 이 된다. 


문제 상황과 같이 CIFAR10에 있는 32 x 32 images를 input으로 주게 되는 경우 <br/>
Conv / Pooling Layer를 거치면서 크기가 바뀌게 된다. <br/>
위와 같은 방법을 통하면 1x1의 shape이 나온다.</br>
7x7로 분류하던 것을 1x1을 FC에 연결하면 정상 동작하기는 어려울 것으로 예측된다<br/>

따라서 d는 틀리고 c가 정답이 되는 것이다. 



# 1-3번

![](/assets/img/2022-01-26-15-56-54.png)
Pooling 연산은 단순히 입력의 size를 줄여주는 기능을 한다는 것을 되새기자.<br/>

max pooling 연산을 취하게 될 경우 해당 필터내의 가장 큰 값만 뽑아내기 때문에 <br/>
비선형에 기여한다고 볼 수 있다. 이렇게 되면 기울기의 다양성이 증가한다. <br/>

# 2번 1~4

![](/assets/img/2022-01-26-15-58-53.png)

1. False<br/>
   Vanila SGD에서는 모멘텀 문제가 발생했고 이를 보완하기 위하여 AdaGRAD가 나온것.
   <br/>

2. False<br/>
   W=ax+b, bias를 주의 하지 않으면 틀리기 좋은 문제였다.

3. True<br/>
   L1, L2 Regularization에 대한 개념을 다시 짚어볼 필요가 있었다. <br/>
   기본적으로 정규화는 overfitting을 예방하고, generalization을 높여주는 역할을 한다.<br/>
   `L1 Regularization` Featurala Selection이 가능하다. Sparse Model에 적합. Convex Optimazation에 유용.<br/>
   미분 불가능한 지점이 존재하므로 gradient-base learning에서는 주의 필요<br/>
   `L2 Regularization` vector에 대해 항상 unique한 값을 도출.<br/>
    특정 feature에 대한 영향을 크게 받지 않을때 사용하면 좋음 

    ![](/assets/img/2022-01-26-16-20-51.png)

4. True<br/>
   `symmetry breaking` 이란 가중치 행렬의 대칭이 파괴되었다는 의미로 <br/>
   비선형성이 추가되는 상황이라고 할 수 있다. 

# 2번 5~8

![](/assets/img/2022-01-26-16-27-20.png)<br/>

    5. False<br/>
       기본적으로 기울기란 소규모 가중치가 있을때 그 값이 살짝 변했을때 손실의 변화를 의미한다. <br/>
          기울기가 -3일때 손실변화가 -3이라는 것의 의미는 가중치의 감소가<br/>

    손실을 -3만큼 증가 시켰다고 해석할 수 있다. <br/>

6. True<br/>
   bias까지 정규화해버리면 비선형성이 사라진다.
7. True<br/>
   tanh의 범위는 [-1, 1] 이므로, 1-z^2 은 항상 [0, 1] 범위에 속한다.
8. True<br/>
   sigmoid ,tanhh, ReLU는 모두 non-decrease 함수이므로 부호가 변화하지 않는다.<br/>
    증가 또는 감소만 하는 함수를 `monotonic` 하다고 하는데 , <br/>
    activation function이 단조(monotonic)일 경우 single-layer model와 연관된 error surface는 convex를 보장.<br/>


# 2번 9~11

![](/assets/img/2022-01-26-16-37-36.png)

  9. True / False 둘 다 가능
     문제가 모호하기 때문에 둘 다 답이 될 수 있다. <br/>
        ReLU 요소 > 0 일 경우 True, >=0 일 경우 Fasle이다. <br/>
 10. False
     손실함수는 일반적으로는 감소하는 것이 맞지만, overshooting의 경우 증가한다.<br/>
 11. Fasle
     kikes는 꺾이는 부분을 의미한다. <br/>
     zero-centered를 사용하는 주된 이유는 gradients를 좀 더 정확히 비교하기 위함이다.<br/>
     kinks를 피하기 위한 다는 설명은 바람직 하지 않다. <br/>

# 3-1번

3번문제는 수학적인 풀이가 많기 때문에 이미지 첨부를 주로 하겠다. 자세한 풀이는 앞서 걸어둔<br/>
링크에서 확인하길 바란다. <br/>

![](/assets/img/2022-01-26-16-42-45.png)
신경망을 이해하기 위해서는 backpropagation을 정확히 이해해야하고, 이 과정은 <br/>
computational graph를 그려보면서 chain rule 을 적용하는 방식으로 이루어진다. <br/>
또한 덧셈, 곱셈노드의 직관적 기능을 이해하면 수월하게 풀이가능하다. <br/>

# 3-2번

![](/assets/img/2022-01-26-16-44-54.png)

pooling 연산은 parameters가 필요없다는 것. FC Layer의 Dimension은 <br/>
channel 수 * 1 이라는 것을 기억하면 어렵지 않게 풀 수 있다. 

# 3-3번

![](/assets/img/2022-01-26-16-46-14.png)
![](/assets/img/2022-01-26-16-46-40.png)
![](/assets/img/2022-01-26-16-47-21.png)
![](/assets/img/2022-01-26-16-47-43.png)

## K-NN

1.  `Image Classification`은 입력 이미지에 대하여 해당 이미지가 속하는 catergory를 찾는 기법<br/>
    `training set`은 image와 label을 가지고, `test set`은 input의 label을 예측한다. 
2.  `K-Nearest Neighbors` classifier는 `training set` 중에서 가장 가까운 샘플을 골라서 label을 예측
3.  K-NN에서 하이퍼 파라미터는 `Distance Metric`과 `K` 이다.
4.  `L1 (Manhattan)`는 특징에 의존적일 때 사용, `L2 (Eucleadean)`는 특징에 의존적이지 않을 때 사용
5.  하이퍼 파라미터를 결정할 때, `Validation set` 을 설정하고, `Test set`은 마지막에 오직 1번만 사용한다.

## Linear Classification  

1. `Linear Classifier`는 `레고 블럭`에 비유가능. `레고 블럭`을 쌓아서 `Nerual Network` 구성

2. 수식으로 다음과 같이 표현 가능하다.

   <p align="center"> 
   ${ 
      f(x, W) = Wx + b
   }$ 
   </p>

3. `x`는 input 이미지, `W`는 이미지에 대한 요약된 정보. `Wx`는 클래스 간 템플릿의 유사도를 측정하는 연산

4. 각 클래스에 대해서 단 하나의 템플릿만 학습하므로 풀지 못하는 여러 문제가 존재

5. 아주 쉽게 이해하고 해석할 수 있는 알고리즘 이라는 의의가 있다. 